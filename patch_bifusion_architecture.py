#!/usr/bin/env python3
"""
BiFusionæ¶æ„çº§ä¿®å¤è¡¥ä¸
ç›´æ¥ä¿®å¤åæ ‡å˜æ¢å’Œèåˆæœºåˆ¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

def patch_bifusion_encoder():
    """åº”ç”¨BiFusionçš„æ¶æ„ä¿®å¤è¡¥ä¸"""
    
    from oneformer3d.bi_fusion_encoder import BiFusionEncoder
    
    # ä¿å­˜åŸå§‹æ–¹æ³•
    original_process_single = BiFusionEncoder._process_single
    
    def fixed_process_single(self, points, img, cam_meta, feat2d_map=None, clip_global=None):
        """ä¿®å¤çš„_process_singleæ–¹æ³•"""
        
        # 1. å‡å°‘åæ ‡å˜æ¢ï¼šç›´æ¥ä½¿ç”¨ç›¸æœºåæ ‡
        xyz_cam = points[:, :3]
        
        # 2. ç®€åŒ–æŠ•å½±ï¼Œå‡å°‘è¯¯å·®ç´¯ç§¯
        if cam_meta.get('intrinsics', None) is not None:
            intr = cam_meta['intrinsics']
            if not torch.is_tensor(intr):
                intr = torch.as_tensor(intr, dtype=xyz_cam.dtype, device=xyz_cam.device)
            
            # ç›´æ¥æŠ•å½±ï¼Œé¿å…åŒé‡å˜æ¢
            valid, uv = self.build_uv_index(xyz_cam, intr, feat2d_map.shape[-2:])
            
            # 3. æ”¹è¿›ç‰¹å¾é‡‡æ ·ï¼šç”¨æœ€è¿‘é‚»å¡«å……
            sampled2d = xyz_cam.new_zeros((xyz_cam.shape[0], 256))
            if valid.any():
                f2d_vis = self.sample_img_feat(feat2d_map.unsqueeze(0), uv[valid])
                sampled2d[valid] = f2d_vis.to(sampled2d.dtype)
                
                # æ–°å¢ï¼šç”¨æœ€è¿‘é‚»å¡«å……æ— æ•ˆç‚¹
                if (~valid).any():
                    # æ‰¾åˆ°æ¯ä¸ªæ— æ•ˆç‚¹æœ€è¿‘çš„æœ‰æ•ˆç‚¹
                    invalid_idx = torch.where(~valid)[0]
                    valid_idx = torch.where(valid)[0]
                    
                    if len(valid_idx) > 0:
                        # è®¡ç®—è·ç¦»çŸ©é˜µ
                        dist = torch.cdist(xyz_cam[invalid_idx], xyz_cam[valid_idx])
                        nearest_idx = dist.argmin(dim=1)
                        sampled2d[invalid_idx] = sampled2d[valid_idx[nearest_idx]]
        else:
            # æ— ç›¸æœºä¿¡æ¯æ—¶ï¼Œä½¿ç”¨é›¶å‘é‡
            sampled2d = xyz_cam.new_zeros((xyz_cam.shape[0], 256))
            valid = torch.zeros(xyz_cam.shape[0], dtype=torch.bool, device=xyz_cam.device)
        
        # 4. 3Dåˆ†æ”¯å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ä½†å¢åŠ ç¨³å®šæ€§ï¼‰
        xyz_world = xyz_cam  # ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨ç›¸æœºåæ ‡ä½œä¸ºä¸–ç•Œåæ ‡
        coords_int = torch.round(xyz_world / self.voxel_size).to(torch.int32)
        coords = torch.cat([torch.zeros(coords_int.size(0), 1, dtype=torch.int32, device=coords_int.device),
                             coords_int], dim=1)
        feats = points[:, 3:6].contiguous()
        
        # æ·»åŠ ç‰¹å¾æ ‡å‡†åŒ–
        feats = F.normalize(feats, dim=-1)
        
        field = ME.TensorField(coordinates=coords, features=feats)
        sparse_tensor = field.sparse()
        feat3d_sparse = self.backbone3d(sparse_tensor)
        feat3d = feat3d_sparse.slice(field).features
        feat3d = self.backbone_adapter(feat3d)
        
        # 5. å‡ ä½•ç¼–ç 
        bbox_size = torch.zeros_like(xyz_world)
        pose_delta = torch.zeros(9, device=xyz_world.device, dtype=xyz_world.dtype)
        height = xyz_world[:, 2:3]
        pe = self.pe_mlp(build_geo_pe(xyz_world, bbox_size, pose_delta, height))
        
        # 6. ç‰¹å¾å¤„ç†
        feat3d = self.simple_neck(feat3d)
        feat3d = self.lin3d(feat3d)
        feat3d = self.ln3d(feat3d)
        
        feat2d = self.lin2d(sampled2d)
        feat2d = self.ln2d(feat2d)
        
        # 7. æ”¹è¿›çš„ç‰¹å¾èåˆ
        f2d_final = self.lin2d_final(torch.cat([feat2d, pe], dim=-1))
        f3d_final = self.lin3d_final(torch.cat([feat3d, pe], dim=-1))
        
        # æ–°çš„è‡ªé€‚åº”èåˆç­–ç•¥
        if self.use_enhanced_gate:
            # è®¡ç®—ç‰¹å¾è´¨é‡å¾—åˆ†
            f2d_quality = torch.sigmoid(self.quality_mlp_2d(f2d_final))  # éœ€è¦æ·»åŠ è¿™ä¸ªå±‚
            f3d_quality = torch.sigmoid(self.quality_mlp_3d(f3d_final))  # éœ€è¦æ·»åŠ è¿™ä¸ªå±‚
            
            # ç»“åˆæœ‰æ•ˆæ€§å’Œè´¨é‡
            valid_weight = valid.float().unsqueeze(-1)
            adaptive_weight = valid_weight * f2d_quality / (f2d_quality + f3d_quality + 1e-8)
            
            fused = adaptive_weight * f2d_final + (1 - adaptive_weight) * f3d_final
            conf = adaptive_weight
        else:
            # å›é€€åˆ°æ”¹è¿›çš„ç®€å•èåˆ
            gate_input = torch.cat([f2d_final, f3d_final], dim=-1)
            gate = torch.sigmoid(self.gate_mlp(gate_input))
            valid_weight = valid.float().unsqueeze(-1)
            # æ›´ä¿å®ˆçš„æ— æ•ˆæƒé‡ï¼šä»0.2é™åˆ°0.1
            gate = gate * valid_weight + 0.1 * (1 - valid_weight)
            fused = gate * f2d_final + (1 - gate) * f3d_final
            conf = gate
        
        return fused, conf, pe, clip_global
    
    # åº”ç”¨è¡¥ä¸
    BiFusionEncoder._process_single = fixed_process_single
    print("ğŸ”§ BiFusionæ¶æ„ä¿®å¤è¡¥ä¸å·²åº”ç”¨")

if __name__ == "__main__":
    patch_bifusion_encoder()
