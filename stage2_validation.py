#!/usr/bin/env python3
"""
Stage 2 BiFusionä¼˜åŒ–éªŒè¯è„šæœ¬
éªŒè¯å¢å¼ºçš„ç›‘æ§Hookå’ŒBiFusionç»Ÿè®¡æ”¶é›†åŠŸèƒ½
"""

import os
import sys
import torch
import traceback
from pathlib import Path

# ç¡®ä¿åœ¨ESAMç›®å½•ä¸‹
os.chdir('/home/nebula/xxy/ESAM')
sys.path.insert(0, os.getcwd())

def test_enhanced_hook():
    """æµ‹è¯•EnhancedTrainingHookçš„æ ¸å¿ƒåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•Enhanced Training Hook...")
    
    try:
        from oneformer3d.enhanced_training_hook import EnhancedTrainingHook
        
        # åˆ›å»ºHookå®ä¾‹
        hook = EnhancedTrainingHook(
            log_interval=1,
            grad_monitor_interval=1,
            detailed_stats=True
        )
        
        print("âœ… Hookå®ä¾‹åŒ–æˆåŠŸ")
        
        # æ¨¡æ‹ŸæŸå¤±ä¿¡æ¯æµ‹è¯•
        mock_loss_info = {
            'loss': 2.5,
            'semantic_loss': 0.8, 
            'instance_loss': 1.2,
            'clip_consistency_loss': 0.3,
            'spatial_consistency_loss': 0.2
        }
        
        detailed_losses = hook._extract_detailed_losses(mock_loss_info)
        print("âœ… è¯¦ç»†æŸå¤±æå–åŠŸèƒ½æ­£å¸¸")
        print(f"   æå–çš„æŸå¤±: {detailed_losses}")
        
        # æµ‹è¯•æŠ•å½±ç»Ÿè®¡æ–¹æ³•
        mock_outputs = {
            'valid_projection_mask': [torch.rand(1000) > 0.3, torch.rand(800) > 0.2]
        }
        
        class MockModel:
            def __init__(self):
                self.module = self
                self.bi_encoder = MockBiFusionEncoder()
        
        class MockBiFusionEncoder:
            def __init__(self):
                self._fusion_stats = {
                    'valid_points_ratio': 0.85,
                    'total_points': 5000,
                    '2d_weight_mean': 0.6,
                    '3d_weight_mean': 0.4
                }
                # æ·»åŠ ç¼ºå¤±çš„æ–¹æ³•å’Œå±æ€§
                self.fusion_gate = MockFusionGate()
                
            def named_modules(self):
                """æ¨¡æ‹Ÿnamed_modulesæ–¹æ³•"""
                return [('fusion_gate', self.fusion_gate)]
                
        class MockFusionGate:
            def __init__(self):
                self._last_alpha = torch.tensor([0.6, 0.7, 0.5, 0.8])  # æ¨¡æ‹Ÿalphaæƒé‡
                self._stats_buffer = [{'2d_ratio': 0.6, '3d_ratio': 0.4}]
        
        mock_model = MockModel()
        proj_stats = hook._extract_projection_stats(mock_model, mock_outputs)
        print("âœ… æŠ•å½±ç»Ÿè®¡æå–åŠŸèƒ½æ­£å¸¸")
        print(f"   æŠ•å½±ç»Ÿè®¡: {proj_stats}")
        
        # æµ‹è¯•èåˆé—¨ç»Ÿè®¡æ–¹æ³•  
        fusion_stats = hook._extract_fusion_stats(mock_model, mock_outputs)
        print("âœ… èåˆé—¨ç»Ÿè®¡æå–åŠŸèƒ½æ­£å¸¸")
        print(f"   èåˆé—¨ç»Ÿè®¡: {fusion_stats}")
        
        print("ğŸ‰ Enhanced Training Hook æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½éªŒè¯é€šè¿‡!")
        
    except Exception as e:
        print(f"âŒ Hookæµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()

def test_bifusion_config():
    """æµ‹è¯•BiFusioné…ç½®æ–‡ä»¶çš„æ­£ç¡®æ€§"""
    print("\nğŸ§ª æµ‹è¯•BiFusioné…ç½®æ–‡ä»¶...")
    
    config_path = "/home/nebula/xxy/ESAM/configs/ESAM_CA/sv_bifusion_scannet200.py"
    
    try:
        # æ£€æŸ¥é…ç½®æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return
            
        # è¯»å–é…ç½®å†…å®¹
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        checks = [
            ('CLIPä¸€è‡´æ€§æŸå¤±', 'ClipConsCriterion', '0.1'),
            ('ç©ºé—´ä¸€è‡´æ€§æŸå¤±', 'spatial_consistency', '0.02'),
            ('5è½®è¯„ä¼°é—´éš”', 'val_interval = 5', None),
            ('å¢å¼ºHookå¯¼å…¥', 'EnhancedTrainingHook', None),
            ('ç»Ÿè®¡æ”¶é›†å¯ç”¨', '_collect_fusion_stats', None),
        ]
        
        for check_name, check_key, expected_value in checks:
            if check_key in content:
                print(f"âœ… {check_name} é…ç½®å­˜åœ¨")
                if expected_value and expected_value in content:
                    print(f"   å€¼è®¾ç½®æ­£ç¡®: {expected_value}")
            else:
                print(f"âš ï¸  {check_name} é…ç½®å¯èƒ½ç¼ºå¤±")
        
        print("ğŸ‰ BiFusioné…ç½®æ–‡ä»¶éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")

def test_auxiliary_losses():
    """æµ‹è¯•è¾…åŠ©æŸå¤±å‡½æ•°"""
    print("\nğŸ§ª æµ‹è¯•è¾…åŠ©æŸå¤±å‡½æ•°...")
    
    try:
        from oneformer3d.auxiliary_loss import SpatialConsistencyLoss, NoViewSupervisionLoss
        
        # æµ‹è¯•ç©ºé—´ä¸€è‡´æ€§æŸå¤±
        spatial_loss = SpatialConsistencyLoss()
        print("âœ… SpatialConsistencyLoss å®ä¾‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ— è§†å›¾ç›‘ç£æŸå¤± (å¦‚æœå­˜åœ¨)
        try:
            nv_loss = NoViewSupervisionLoss()
            print("âœ… NoViewSupervisionLoss å®ä¾‹åŒ–æˆåŠŸ")
        except:
            print("â„¹ï¸  NoViewSupervisionLoss æš‚æœªå®ç° (æ­£å¸¸)")
        
        print("ğŸ‰ è¾…åŠ©æŸå¤±å‡½æ•°éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è¾…åŠ©æŸå¤±æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """ä¸»éªŒè¯æµç¨‹"""
    print("ğŸš€ ESAM Stage 2 BiFusionä¼˜åŒ–éªŒè¯")
    print("=" * 60)
    
    # ç¯å¢ƒæ£€æŸ¥
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ Pythonè·¯å¾„: {sys.executable}")
    print(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"ğŸ¯ CUDAå¯ç”¨: {torch.cuda.is_available()}")
    print("-" * 60)
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    test_enhanced_hook()
    test_bifusion_config()
    test_auxiliary_losses()
    
    print("\n" + "=" * 60)
    print("âœ¨ Stage 2 éªŒè¯å®Œæˆ! ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡ŒBiFusionè®­ç»ƒ")
    print("ğŸ“‹ å»ºè®®ä¸‹ä¸€æ­¥:")
    print("   1. è¿è¡Œå®Œæ•´è®­ç»ƒä»¥éªŒè¯ç›‘æ§åŠŸèƒ½")
    print("   2. è§‚å¯Ÿfusion gateç»Ÿè®¡å’ŒæŠ•å½±æœ‰æ•ˆç‡")
    print("   3. ç›‘æ§æ¢¯åº¦å¥åº·åº¦å’Œlossæ”¶æ•›æ€§")
    print("   4. æ ¹æ®ç»Ÿè®¡æ•°æ®è¿›è¡Œå‚æ•°å¾®è°ƒ")

if __name__ == "__main__":
    main()
