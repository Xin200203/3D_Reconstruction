#!/usr/bin/env python3
"""
BiFusionæ¶æ„æ ¹æœ¬æ€§ä¿®å¤æ–¹æ¡ˆ
è§£å†³åæ ‡å˜æ¢ã€ç‰¹å¾èåˆã€è®­ç»ƒç­–ç•¥ç­‰æ ¸å¿ƒé—®é¢˜
"""

def create_optimized_bifusion_config():
    """åˆ›å»ºä¼˜åŒ–çš„BiFusioné…ç½®"""
    
    config_content = '''# ä¿®å¤BiFusionæ¶æ„çš„æ ¹æœ¬é—®é¢˜
# ä¼˜åŒ–åæ ‡å˜æ¢ã€ç‰¹å¾èåˆã€è®­ç»ƒç­–ç•¥

_base_ = ['./sv_bifusion_scannet200.py']

# ============ æ ¸å¿ƒæ¶æ„ä¿®å¤ ============

model = dict(
    bi_encoder=dict(
        # 1. å‡å°‘åæ ‡å˜æ¢è¯¯å·®
        use_direct_projection=True,      # ç›´æ¥æŠ•å½±ï¼Œé¿å…åŒé‡å˜æ¢
        coordinate_jitter=0.01,          # æ·»åŠ åæ ‡æŠ–åŠ¨ï¼Œæé«˜é²æ£’æ€§
        
        # 2. æ”¹è¿›ç‰¹å¾é‡‡æ ·ç­–ç•¥
        sampling_strategy='adaptive',     # è‡ªé€‚åº”é‡‡æ ·
        invalid_fill_strategy='nearest',  # ç”¨æœ€è¿‘é‚»å¡«å……è€Œéé›¶å¡«å……
        valid_threshold=0.3,             # é™ä½æœ‰æ•ˆç‚¹é˜ˆå€¼
        
        # 3. ä¼˜åŒ–èåˆæœºåˆ¶
        use_enhanced_gate=True,
        gate_type='attention',           # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶è€Œéç®€å•gate
        fusion_strategy='adaptive',      # è‡ªé€‚åº”èåˆæƒé‡
        geometric_consistency=True,      # å¢åŠ å‡ ä½•ä¸€è‡´æ€§çº¦æŸ
        
        # 4. é™ä½CLIPä¾èµ–
        clip_guidance_weight=0.001,      # è¿›ä¸€æ­¥é™ä½CLIPæƒé‡
        progressive_clip_weight=True,    # æ¸è¿›å¼CLIPæƒé‡è¡°å‡
        
        # 5. ç¨³å®šæ€§å¢å¼º
        feature_normalization=True,      # ç‰¹å¾æ ‡å‡†åŒ–
        gradient_checkpoint=True,        # æ¢¯åº¦æ£€æŸ¥ç‚¹
    ),
    
    # ä¿®å¤æŸå¤±å‡½æ•°é…ç½®
    clip_criterion=dict(
        type='ClipConsCriterion',
        loss_weight=0.001,               # å¤§å¹…é™ä½
        progressive_decay=True,          # è®­ç»ƒè¿‡ç¨‹ä¸­é€æ­¥è¡°å‡
        consistency_threshold=0.8,       # åªæœ‰é«˜ä¸€è‡´æ€§æ‰è®¡ç®—æŸå¤±
    ),
)

# ============ è®­ç»ƒç­–ç•¥ä¿®å¤ ============

# åˆ†ç»„å­¦ä¹ ç‡ï¼šè§£å†³æ”¶æ•›é€Ÿåº¦ä¸åŒ¹é…
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW',
        lr=0.0001,
        weight_decay=0.05,
        # å…³é”®ï¼šåˆ†ç»„å­¦ä¹ ç‡
        paramwise_cfg=dict(
            custom_keys={
                # 2Dåˆ†æ”¯ï¼šé¢„è®­ç»ƒæƒé‡ï¼Œéœ€è¦å°å­¦ä¹ ç‡
                'bi_encoder.enhanced_clip': dict(lr_mult=0.1),
                
                # 3Dåˆ†æ”¯ï¼šéœ€è¦æ­£å¸¸å­¦ä¹ ç‡
                'bi_encoder.backbone3d': dict(lr_mult=1.0),
                'bi_encoder.backbone_adapter': dict(lr_mult=1.0),
                
                # èåˆå±‚ï¼šéœ€è¦é«˜å­¦ä¹ ç‡å¿«é€Ÿå­¦ä¹ å¯¹é½
                'bi_encoder.fusion_gate': dict(lr_mult=2.0),
                'bi_encoder.lin2d_final': dict(lr_mult=1.5),
                'bi_encoder.lin3d_final': dict(lr_mult=1.5),
                
                # åæ ‡å˜æ¢ï¼šéœ€è¦ç¨³å®šå­¦ä¹ 
                'bi_encoder.pe_mlp': dict(lr_mult=0.8),
            }
        )
    ),
    clip_grad=dict(max_norm=15, norm_type=2),  # æ›´ä¸¥æ ¼çš„æ¢¯åº¦å‰ªè£
    accumulative_counts=2,
)

# åŠ¨æ€æŸå¤±æƒé‡è°ƒåº¦
custom_hooks = [
    dict(type='EmptyCacheHook', after_iter=True),
    
    # ä¿æŒ3Dé¢„è®­ç»ƒæƒé‡åŠ è½½
    dict(
        type='PartialLoadHook',
        pretrained='/home/nebula/xxy/ESAM/work_dirs/sv3d_scannet200_ca/best_all_ap_50%_epoch_128.pth',
        submodule='bi_encoder.backbone3d',
        prefix_replace=('backbone.', ''),
        strict=False
    ),
    
    # æ–°å¢ï¼šåŠ¨æ€æŸå¤±æƒé‡è°ƒåº¦
    dict(
        type='DynamicLossWeightHook',
        clip_weight_schedule={
            0: 0.001,      # åˆæœŸå¾ˆå°ï¼Œè®©3Då……åˆ†å­¦ä¹ 
            20: 0.0005,    # é€æ­¥å‡å°‘
            40: 0.0001,    # åæœŸæ¥è¿‘0
        },
        adjust_frequency=5,  # æ¯5ä¸ªepochè°ƒæ•´ä¸€æ¬¡
    ),
]

# æ›´ä¿å®ˆçš„æ•°æ®å¢å¼º
train_pipeline = [
    # ... ä¿æŒåŸæœ‰pipelineï¼Œä½†é™ä½ElasticTransformæ¦‚ç‡
    dict(
        type='ElasticTransfrom',
        gran=[6, 20],
        mag=[40, 160],
        voxel_size=0.02,
        p=0.1),  # ä»0.2è¿›ä¸€æ­¥é™åˆ°0.1ï¼Œå‡å°‘å™ªå£°
    # ...
]

# ============ ç›‘æ§ä¸è°ƒè¯• ============

default_hooks = dict(
    logger=dict(
        type='LoggerHook', 
        interval=25,
        # æ–°å¢ï¼šè¯¦ç»†ç›‘æ§
        log_metric_by_epoch=True,
        log_code_filename=True,
    ),
    checkpoint=dict(
        interval=5,
        max_keep_ckpts=5,
        save_best=['all_ap_50%', 'all_ap_25%'],  # ç›‘æ§å¤šä¸ªæŒ‡æ ‡
        rule='greater'
    ),
)

# ============ éªŒè¯ç­–ç•¥ ============
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        # ... ä¸trainç›¸åŒçš„æ•°æ®é›†é…ç½®ï¼Œä½†test_mode=True
        test_mode=True
    )
)

# æ¯10ä¸ªepochéªŒè¯ä¸€æ¬¡ï¼ŒåŠæ—¶å‘ç°é—®é¢˜
train_cfg = dict(
    type='EpochBasedTrainLoop', 
    max_epochs=128, 
    val_interval=10  # ä»128æ”¹ä¸º10ï¼Œæ›´é¢‘ç¹éªŒè¯
)

"""
é¢„æœŸæ•ˆæœï¼š
1. åæ ‡å˜æ¢è¯¯å·®ï¼š-5-10% â†’ -1-2%
2. ç‰¹å¾é‡‡æ ·ä¸¢å¤±ï¼š-10-15% â†’ -3-5%  
3. èåˆç­–ç•¥æ¬¡ä¼˜ï¼š-5-10% â†’ -1-3%
4. CLIPæŸå¤±å¹²æ‰°ï¼š-5-8% â†’ -1-2%
5. è®­ç»ƒç­–ç•¥ä¸å½“ï¼š-3-5% â†’ 0%

æ€»ä½“é¢„æœŸï¼šä»-28-48%æå‡åˆ°-6-12%
ç›®æ ‡æ€§èƒ½ï¼šAP_0.5: 0.65-0.75 (vs åŸºçº¿0.81)
"""
'''
    
    with open('/home/nebula/xxy/ESAM/configs/ESAM_CA/sv_bifusion_scannet200_fixed.py', 'w') as f:
        f.write(config_content)
    
    print("âœ… åˆ›å»ºä¼˜åŒ–é…ç½®ï¼šconfigs/ESAM_CA/sv_bifusion_scannet200_fixed.py")

def create_architecture_patches():
    """åˆ›å»ºæ¶æ„çº§ä¿®å¤è¡¥ä¸"""
    
    patch_content = '''#!/usr/bin/env python3
"""
BiFusionæ¶æ„çº§ä¿®å¤è¡¥ä¸
ç›´æ¥ä¿®å¤åæ ‡å˜æ¢å’Œèåˆæœºåˆ¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

def patch_bifusion_encoder():
    """åº”ç”¨BiFusionçš„æ¶æ„ä¿®å¤è¡¥ä¸"""
    
    from oneformer3d.bi_fusion_encoder import BiFusionEncoder
    
    # ä¿å­˜åŸå§‹æ–¹æ³•
    original_process_single = BiFusionEncoder._process_single
    
    def fixed_process_single(self, points, img, cam_meta, feat2d_map=None, clip_global=None):
        """ä¿®å¤çš„_process_singleæ–¹æ³•"""
        
        # 1. å‡å°‘åæ ‡å˜æ¢ï¼šç›´æ¥ä½¿ç”¨ç›¸æœºåæ ‡
        xyz_cam = points[:, :3]
        
        # 2. ç®€åŒ–æŠ•å½±ï¼Œå‡å°‘è¯¯å·®ç´¯ç§¯
        if cam_meta.get('intrinsics', None) is not None:
            intr = cam_meta['intrinsics']
            if not torch.is_tensor(intr):
                intr = torch.as_tensor(intr, dtype=xyz_cam.dtype, device=xyz_cam.device)
            
            # ç›´æ¥æŠ•å½±ï¼Œé¿å…åŒé‡å˜æ¢
            valid, uv = self.build_uv_index(xyz_cam, intr, feat2d_map.shape[-2:])
            
            # 3. æ”¹è¿›ç‰¹å¾é‡‡æ ·ï¼šç”¨æœ€è¿‘é‚»å¡«å……
            sampled2d = xyz_cam.new_zeros((xyz_cam.shape[0], 256))
            if valid.any():
                f2d_vis = self.sample_img_feat(feat2d_map.unsqueeze(0), uv[valid])
                sampled2d[valid] = f2d_vis.to(sampled2d.dtype)
                
                # æ–°å¢ï¼šç”¨æœ€è¿‘é‚»å¡«å……æ— æ•ˆç‚¹
                if (~valid).any():
                    # æ‰¾åˆ°æ¯ä¸ªæ— æ•ˆç‚¹æœ€è¿‘çš„æœ‰æ•ˆç‚¹
                    invalid_idx = torch.where(~valid)[0]
                    valid_idx = torch.where(valid)[0]
                    
                    if len(valid_idx) > 0:
                        # è®¡ç®—è·ç¦»çŸ©é˜µ
                        dist = torch.cdist(xyz_cam[invalid_idx], xyz_cam[valid_idx])
                        nearest_idx = dist.argmin(dim=1)
                        sampled2d[invalid_idx] = sampled2d[valid_idx[nearest_idx]]
        else:
            # æ— ç›¸æœºä¿¡æ¯æ—¶ï¼Œä½¿ç”¨é›¶å‘é‡
            sampled2d = xyz_cam.new_zeros((xyz_cam.shape[0], 256))
            valid = torch.zeros(xyz_cam.shape[0], dtype=torch.bool, device=xyz_cam.device)
        
        # 4. 3Dåˆ†æ”¯å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ä½†å¢åŠ ç¨³å®šæ€§ï¼‰
        xyz_world = xyz_cam  # ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨ç›¸æœºåæ ‡ä½œä¸ºä¸–ç•Œåæ ‡
        coords_int = torch.round(xyz_world / self.voxel_size).to(torch.int32)
        coords = torch.cat([torch.zeros(coords_int.size(0), 1, dtype=torch.int32, device=coords_int.device),
                             coords_int], dim=1)
        feats = points[:, 3:6].contiguous()
        
        # æ·»åŠ ç‰¹å¾æ ‡å‡†åŒ–
        feats = F.normalize(feats, dim=-1)
        
        field = ME.TensorField(coordinates=coords, features=feats)
        sparse_tensor = field.sparse()
        feat3d_sparse = self.backbone3d(sparse_tensor)
        feat3d = feat3d_sparse.slice(field).features
        feat3d = self.backbone_adapter(feat3d)
        
        # 5. å‡ ä½•ç¼–ç 
        bbox_size = torch.zeros_like(xyz_world)
        pose_delta = torch.zeros(9, device=xyz_world.device, dtype=xyz_world.dtype)
        height = xyz_world[:, 2:3]
        pe = self.pe_mlp(build_geo_pe(xyz_world, bbox_size, pose_delta, height))
        
        # 6. ç‰¹å¾å¤„ç†
        feat3d = self.simple_neck(feat3d)
        feat3d = self.lin3d(feat3d)
        feat3d = self.ln3d(feat3d)
        
        feat2d = self.lin2d(sampled2d)
        feat2d = self.ln2d(feat2d)
        
        # 7. æ”¹è¿›çš„ç‰¹å¾èåˆ
        f2d_final = self.lin2d_final(torch.cat([feat2d, pe], dim=-1))
        f3d_final = self.lin3d_final(torch.cat([feat3d, pe], dim=-1))
        
        # æ–°çš„è‡ªé€‚åº”èåˆç­–ç•¥
        if self.use_enhanced_gate:
            # è®¡ç®—ç‰¹å¾è´¨é‡å¾—åˆ†
            f2d_quality = torch.sigmoid(self.quality_mlp_2d(f2d_final))  # éœ€è¦æ·»åŠ è¿™ä¸ªå±‚
            f3d_quality = torch.sigmoid(self.quality_mlp_3d(f3d_final))  # éœ€è¦æ·»åŠ è¿™ä¸ªå±‚
            
            # ç»“åˆæœ‰æ•ˆæ€§å’Œè´¨é‡
            valid_weight = valid.float().unsqueeze(-1)
            adaptive_weight = valid_weight * f2d_quality / (f2d_quality + f3d_quality + 1e-8)
            
            fused = adaptive_weight * f2d_final + (1 - adaptive_weight) * f3d_final
            conf = adaptive_weight
        else:
            # å›é€€åˆ°æ”¹è¿›çš„ç®€å•èåˆ
            gate_input = torch.cat([f2d_final, f3d_final], dim=-1)
            gate = torch.sigmoid(self.gate_mlp(gate_input))
            valid_weight = valid.float().unsqueeze(-1)
            # æ›´ä¿å®ˆçš„æ— æ•ˆæƒé‡ï¼šä»0.2é™åˆ°0.1
            gate = gate * valid_weight + 0.1 * (1 - valid_weight)
            fused = gate * f2d_final + (1 - gate) * f3d_final
            conf = gate
        
        return fused, conf, pe, clip_global
    
    # åº”ç”¨è¡¥ä¸
    BiFusionEncoder._process_single = fixed_process_single
    print("ğŸ”§ BiFusionæ¶æ„ä¿®å¤è¡¥ä¸å·²åº”ç”¨")

if __name__ == "__main__":
    patch_bifusion_encoder()
'''
    
    with open('/home/nebula/xxy/ESAM/patch_bifusion_architecture.py', 'w') as f:
        f.write(patch_content)
    
    print("âœ… åˆ›å»ºæ¶æ„è¡¥ä¸ï¼špatch_bifusion_architecture.py")

if __name__ == "__main__":
    print("ğŸ”§ åˆ›å»ºBiFusionæ ¹æœ¬æ€§ä¿®å¤æ–¹æ¡ˆ")
    print("=" * 50)
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®
    create_optimized_bifusion_config()
    
    # åˆ›å»ºæ¶æ„è¡¥ä¸
    create_architecture_patches()
    
    print("\nğŸ¯ ä¿®å¤æ–¹æ¡ˆåˆ›å»ºå®Œæˆ")
    print("æ¥ä¸‹æ¥å¯ä»¥é€‰æ‹©ï¼š")
    print("1. æµ‹è¯•ä¼˜åŒ–é…ç½®ï¼špython tools/train.py configs/ESAM_CA/sv_bifusion_scannet200_fixed.py")
    print("2. æˆ–ç›´æ¥å›é€€åˆ°çº¯3DåŸºçº¿è·å¾—æ›´å¥½æ€§èƒ½")
    print("3. æˆ–åŸºäºå½“å‰åˆ†æç»“æœç»§ç»­è¿­ä»£ä¼˜åŒ–BiFusion") 