# Copied from mmdet3d/models/data_preprocessors/data_preprocessor.py
import torch
import numpy as np
import os
from mmdet3d.models.data_preprocessors.data_preprocessor import \
    Det3DDataPreprocessor
from mmdet3d.registry import MODELS


@MODELS.register_module()
class Det3DDataPreprocessor_(Det3DDataPreprocessor):
    """
    We add only this 2 lines:
    if 'elastic_coords' in inputs:
        batch_inputs['elastic_coords'] = inputs['elastic_coords']
    """
    def simple_process(self, data, training=False):
        """Perform normalization, padding and bgr2rgb conversion for img data
        based on ``BaseDataPreprocessor``, and voxelize point cloud if `voxel`
        is set to be True.

        Args:
            data (dict): Data sampled from dataloader.
            training (bool): Whether to enable training time augmentation.
                Defaults to False.

        Returns:
            dict: Data in the same format as the model input.
        """
        # æå–æ ¸å¿ƒæ•°æ®
        inputs = data.get('inputs', {})
        
        if 'img' in data['inputs']:
            batch_pad_shape = self._get_pad_shape(data)

        data = self.collate_data(data)
        inputs, data_samples = data['inputs'], data['data_samples']
        batch_inputs = dict()

        if 'points' in inputs:
            batch_inputs['points'] = inputs['points']

            if self.voxel:
                voxel_dict = self.voxelize(inputs['points'], data_samples)
                batch_inputs['voxels'] = voxel_dict

        if 'elastic_coords' in inputs:
            batch_inputs['elastic_coords'] = inputs['elastic_coords']

        if 'clip_pix' in inputs:
            batch_inputs['clip_pix'] = inputs['clip_pix']
        if 'clip_global' in inputs:
            batch_inputs['clip_global'] = inputs['clip_global']

        if 'imgs' in inputs:
            imgs = inputs['imgs']
            
            # ç»Ÿä¸€å¤„ç†å„ç§å›¾åƒæ ¼å¼
            tensor_imgs = []
            
            if isinstance(imgs, list) and len(imgs) > 0:
                # æ£€æŸ¥æ˜¯å¦æ˜¯tupleæ ¼å¼ï¼ˆPack3DDetInputs_çš„å¤„ç†ç»“æœï¼‰
                if len(imgs) == 1 and isinstance(imgs[0], tuple):
                    # å±•å¼€tupleä¸­çš„å›¾åƒ
                    tuple_imgs = imgs[0]
                    
                    for i, img in enumerate(tuple_imgs):
                        if isinstance(img, torch.Tensor):
                            # ç¡®ä¿tensoræ˜¯æ­£ç¡®çš„æ ¼å¼ (C, H, W)
                            if img.dim() == 3 and img.shape[0] in [1, 3]:
                                tensor_imgs.append(img)
                    
                    # å¤„ç†cam_infoï¼Œä¿æŒbatchä¸­æ¯ä¸ªæ ·æœ¬çš„ç‹¬ç«‹æ€§
                    if 'cam_info' in inputs:
                        cam_info = inputs['cam_info']
                        
                        # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†clip_pixæ·»åŠ åˆ°cam_infoä¸­ä¾›BiFusionä½¿ç”¨
                        if 'clip_pix' in inputs:
                            clip_pix = inputs['clip_pix']
                            # ç¡®ä¿cam_infoæ˜¯åˆ—è¡¨æ ¼å¼
                            if isinstance(cam_info, list):
                                # å¯¹æ¯ä¸ªæ ·æœ¬çš„cam_infoæ·»åŠ clip_pix
                                for i, cam_meta in enumerate(cam_info):
                                    if isinstance(cam_meta, dict):
                                        # å•å¸§ï¼šç›´æ¥æ·»åŠ clip_pix (åº”è¯¥æ˜¯å•ä¸ªtensor)
                                        if torch.is_tensor(clip_pix):
                                            cam_meta['clip_pix'] = clip_pix
                                        elif isinstance(clip_pix, list) and len(clip_pix) > i:
                                            # å¦‚æœclip_pixæ˜¯åˆ—è¡¨ï¼Œå–å¯¹åº”çš„tensor
                                            cam_meta['clip_pix'] = clip_pix[i] if i < len(clip_pix) else clip_pix[0]
                                        else:
                                            cam_meta['clip_pix'] = clip_pix
                            elif isinstance(cam_info, dict):
                                # å•ä¸ªæ ·æœ¬çš„æƒ…å†µ
                                if torch.is_tensor(clip_pix):
                                    cam_info['clip_pix'] = clip_pix
                                elif isinstance(clip_pix, list) and len(clip_pix) > 0:
                                    cam_info['clip_pix'] = clip_pix[0]
                                else:
                                    cam_info['clip_pix'] = clip_pix
                                cam_info = [cam_info]  # è½¬æ¢ä¸ºåˆ—è¡¨
                                
                        batch_inputs['cam_info'] = cam_info
                        if os.environ.get('BIFUSION_DEBUG_CAMINFO'):
                            print(f"[Det3DDataPreprocessor_] tuple imgs cam_info len={len(cam_info)}")
                
                else:
                    # å¤„ç†å…¶ä»–æ ¼å¼çš„å›¾åƒåˆ—è¡¨
                    for i, img in enumerate(imgs):
                        processed_img = self._process_single_image(img, i)
                        if processed_img is not None:
                            tensor_imgs.append(processed_img)
                    
                    # å¤„ç†cam_info
                    if 'cam_info' in inputs:
                        cam_info = inputs['cam_info']
                        
                        # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†clip_pixæ·»åŠ åˆ°cam_infoä¸­ä¾›BiFusionä½¿ç”¨
                        if 'clip_pix' in inputs:
                            clip_pix = inputs['clip_pix']
                            if isinstance(cam_info, list):
                                for i, cam_meta in enumerate(cam_info):
                                    if isinstance(cam_meta, dict):
                                        cam_meta['clip_pix'] = clip_pix
                            elif isinstance(cam_info, dict):
                                cam_info['clip_pix'] = clip_pix
                                
                        batch_inputs['cam_info'] = cam_info
                        if os.environ.get('BIFUSION_DEBUG_CAMINFO'):
                            print(f"[Det3DDataPreprocessor_] list imgs cam_info len={len(cam_info)}")
            
            # éªŒè¯æœ€ç»ˆçš„å›¾åƒåˆ—è¡¨
            if len(tensor_imgs) == 0:
                raise ValueError("No valid images found after preprocessing")
            
            batch_inputs['imgs'] = tensor_imgs
            if os.environ.get('BIFUSION_DEBUG_CAMINFO'):
                print(f"[Det3DDataPreprocessor_] batch imgs={len(tensor_imgs)}")

        elif 'img' in inputs:
            # åŸæ¥çš„ img å¤„ç†é€»è¾‘
            batch_pad_shape = self._get_pad_shape(data)
            imgs = inputs['img']

            if data_samples is not None:
                # NOTE the batched image size information may be useful, e.g.
                # in DETR, this is needed for the construction of masks, which
                # is then used for the transformer_head.
                batch_input_shape = tuple(imgs[0].size()[-2:])
                for data_sample, pad_shape in zip(data_samples,
                                                  batch_pad_shape):
                    data_sample.set_metainfo({
                        'batch_input_shape': batch_input_shape,
                        'pad_shape': pad_shape
                    })

                if hasattr(self, 'boxtype2tensor') and self.boxtype2tensor:
                    from mmdet.models.utils.misc import \
                        samplelist_boxtype2tensor
                    samplelist_boxtype2tensor(data_samples)
                elif hasattr(self, 'boxlist2tensor') and self.boxlist2tensor:
                    # æŸäº›ç‰ˆæœ¬çš„ mmdet å¹¶æœªå®ç° `samplelist_boxlist2tensor`ï¼Œ
                    # è¿™é‡Œä½¿ç”¨ tryâ€“except ä¿æŒå‘åå…¼å®¹ï¼Œé¿å…é™æ€åˆ†ææŠ¥é”™ã€‚
                    try:
                        from mmdet.models.utils.misc import samplelist_boxlist2tensor  # type: ignore
                    except ImportError:  # fallback to same impl as boxtype2tensor
                        from mmdet.models.utils.misc import samplelist_boxtype2tensor as samplelist_boxlist2tensor  # type: ignore
                    samplelist_boxlist2tensor(data_samples)
                if self.pad_mask:
                    self.pad_gt_masks(data_samples)

                if self.pad_seg:
                    self.pad_gt_sem_seg(data_samples)

            if training and self.batch_augments is not None:
                for batch_aug in self.batch_augments:
                    imgs, data_samples = batch_aug(imgs, data_samples)
            batch_inputs['img'] = imgs
        
        if 'img_paths' in inputs:
            img_paths = []
            for batch_idx in range(len(inputs['img_paths'][0])):
                batch_paths = [paths[batch_idx] for paths in inputs['img_paths']]
                img_paths.append(batch_paths)
            batch_inputs['img_paths'] = img_paths
        
        if 'img_path' in inputs:
            batch_inputs['img_path'] = inputs['img_path']
        return {'inputs': batch_inputs, 'data_samples': data_samples}

    def _process_single_image(self, img, idx):
        """å¤„ç†å•ä¸ªå›¾åƒï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼"""
        try:
            # å¤„ç†tupleç±»å‹ - è¿™æ˜¯Pack3DDetInputs_å¤„ç†åçš„æ ¼å¼
            if isinstance(img, tuple):
                # tupleé€šå¸¸æ˜¯(tensor, dtype, shape)æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦ç¬¬ä¸€ä¸ªå…ƒç´ 
                if len(img) > 0 and isinstance(img[0], torch.Tensor):
                    return img[0]
                else:
                    # å°è¯•é‡æ„
                    if len(img) >= 3:  # (data, dtype, shape)
                        try:
                            reconstructed = torch.tensor(img[0], dtype=img[1])
                            if len(img) > 2:
                                reconstructed = reconstructed.view(img[2])
                            return reconstructed
                        except Exception:
                            pass
            
            elif isinstance(img, torch.Tensor):
                return img
            
            elif hasattr(img, 'size'):
                # å¯èƒ½æ˜¯PILå›¾åƒæˆ–numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºtensor
                if hasattr(img, 'convert'):  # PIL Image
                    img_array = np.array(img.convert('RGB'))
                    return torch.from_numpy(img_array).permute(2, 0, 1).float()
                else:  # numpy array
                    if len(img.shape) == 3 and img.shape[-1] == 3:  # (H,W,C)
                        return torch.from_numpy(img).permute(2, 0, 1).float()
                    else:  # (C,H,W)
                        return torch.from_numpy(img).float()
            
            else:
                # å…¶ä»–æƒ…å†µï¼Œå°è¯•è½¬æ¢
                if hasattr(img, 'dtype') and hasattr(img, 'shape'):
                    return img.float() if hasattr(img, 'float') else img
                elif hasattr(img, '__array__'):
                    try:
                        arr = np.array(img)
                        return torch.from_numpy(arr).float()
                    except Exception:
                        pass
                        
        except Exception:
            pass
            
        return None
