本文件用于指导 **ESAM 单帧（SV）实例分割**的系统性 ablation，目标是把“重复实例（duplicate）”与“≥100 点大物体的 0<iou<0.5 卡线”两条主矛盾拆开，逐轮排除假设，为后续 online 关联/重建提供**少而精**的单帧供给。

适用范围：
- **仅单帧 SV 配置**：`configs/ESAM_CA/ESAM_sv_scannet200_CA_dino.py`
- 评测入口：`tools/test.py`
- 单帧实例后处理实现：`oneformer3d/mixformer3d.py` 的 `predict_by_feat_instance()`（`topk_insts / obj_normalization / matrix_nms / sp_score_thr / inst_score_thr / npoint_thr` 都在这里生效）
- 诊断输出实现：`oneformer3d/unified_metric.py`（`instance_diagnostics/instance_error_diagnostics.json` + `instance_error_diagnostics_raw.npz`）

---

# 1. 背景：单帧输出路径（必须对齐代码）

单帧实例输出关键步骤（代码位置会随模型类型不同而略有差异）：
- SV 单帧模型（本配置 `ScanNet200MixFormer3D`）：`oneformer3d/mixformer3d.py` 的 `predict_by_feat_instance()`（约 `#L1123` 附近）
- Online 版本（`ScanNet200MixFormer3D_Online`）：`oneformer3d/mixformer3d.py` 的 `predict_by_feat_instance()`（约 `#L2066` 附近）

共同逻辑如下：
1. `scores = softmax(cls_preds)[:, :-1]`（如有 `out['scores']` 则乘上）→ `topk_insts` 取 topK（`model.test_cfg.topk_insts`）
2. （可选）`obj_normalization`：计算 `mask_scores`（正区域平均置信度）并乘回 `scores`（`model.test_cfg.obj_normalization`）
3. （可选）`mask_matrix_nms`（目前仅传 `kernel`：`model.test_cfg.matrix_nms_kernel`）
4. **二值化**：`mask_pred = sigmoid(mask_logits) > sp_score_thr`（`model.test_cfg.sp_score_thr`）
5. **过滤**：`inst_score_thr`（score阈值）与 `npoint_thr`（最小点数阈值）

因此本文件所有实验都只在这些“旋钮”上做最小改动，保证每次实验只排除一个假设。

补充（2025-12-25 更新）：为了解决已证实的 **score–IoU 不对齐** 与 **best-IoU-rank 长尾**（好候选存在但 rank 靠后），已新增两类可控后处理模块：
- **quality-aware selection（rerank 前置到 topK）**：`model.test_cfg.selection.*`
  - 关键点：必须在 `topK` 前计算新的 `select_scores`，否则只能改变输出排序/AP，无法改变“好候选是否进 topK”。
  - 同时会输出 `instance_select_scores`（用于诊断侧 `oracle@K` / `best-IoU-rank` 统计）。
- **copy-suppress（显式去重，会真正丢掉 mask）**：`model.test_cfg.copy_suppress.*`
  - 关键点：与 Matrix-NMS（当前多为 score 衰减）不同，它会基于 mask IoU 阈值直接 drop “纯拷贝”候选，目标是降低 `hit_ge2` 且尽量不抬高红线。

---

# 2. 固定评测设置（不要混变量）

## 2.1 固定模型与数据
- Config：`configs/ESAM_CA/ESAM_sv_scannet200_CA_dino.py`
- Checkpoint：按你当前要评测的模型路径（例如 `work_dirs/.../epoch_35.pth`）
- 数据：SV val（config 里 `scannet200_sv_oneformer3d_infos_val_dino.pkl`）

## 2.2 固定 diagnostics 参数（用于横向可比）
建议每次都固定如下（除非专门做阈值敏感性实验）：
- `test_evaluator.diagnostics.enable=True`
- `test_evaluator.diagnostics.out_dir=<每次实验独立目录>`
- `test_evaluator.diagnostics.iou_thr=0.5`
- `test_evaluator.diagnostics.iou_lo_thr=0.1`
- `test_evaluator.diagnostics.gt_size_thr=100`
- 其余 purity/区间参数保持默认或固定

额外建议（用于 rerank 实验的“硬证据”）：
- `test_evaluator.diagnostics.score_source=instance_select_scores`
  - 解释：`oracle@K` 与 `best-IoU-rank` 需要用“参与 topK 选择的分数”来排序；否则你会看到 AP 在变，但 rank 统计几乎不动（假改进）。

---

# 3. 核心指标（每次实验必须记录）

以你当前 diagnostics JSON 为准（`instance_diagnostics/instance_error_diagnostics.json`）：

## 3.1 单帧三大核心指标（主判据）
只盯 **≥100 点桶**为主（避免小物体污染结论）：
1. **大物体卡线率**：`miss_rates.gt_best_iou_0_0p5_rate_ge_100`（目标：下降）
2. **重复率**：`diagnosis.rates.gt_hit_ge2_rate`（目标：下降）
3. **弱命中保真（别把有用候选剪没）**：`miss_rates.gt_hit_zero_rate_iou_lo_ge_100`（目标：保持极低，接近 0）

## 3.2 副作用报警器（建议每次都看）
1. **真·漏检（≥100）**：`miss_rates.gt_best_iou_zero_rate_ge_100`（目标：接近 0，且不能上升）
2. **整体噪声倾向**：看 `purity_low_rate / purity_high_rate`（`diagnosis.rates`）
3. **低质预测占比（强烈建议记录）**：`pred_strong_gt_cnt==0` 的比例（在 `instance_error_diagnostics_raw.npz`）
   - 该量表示“对任何 GT 都没达到 IoU≥0.5”的预测占比，若飙升通常意味着你在制造 FP/噪声候选。

### 从 `npz` 计算 `pred_strong0_rate` 的命令（每次实验后跑一次）
```bash
/home/nebula/miniconda3/envs/ESAM/bin/python - <<'PY'
import numpy as np, sys
npz = np.load("instance_diagnostics/instance_error_diagnostics_raw.npz")
x = npz["pred_strong_gt_cnt"]
print("pred_strong0_rate", float((x==0).mean()), "N", x.size)
PY
```

---

# 4. 统一运行命令模板（每次实验只改 cfg-options）

建议每次实验都写入独立的 `out_dir`，避免覆盖：

```bash
CUDA_VISIBLE_DEVICES=0 python tools/test.py \
  configs/ESAM_CA/ESAM_sv_scannet200_CA_dino.py \
  <CHECKPOINT.pth> \
  --work-dir work_dirs/ESAM_sv_scannet200_CA_dino_eval_<EXP_NAME> \
  --cfg-options \
    test_evaluator.diagnostics.enable=True \
    test_evaluator.diagnostics.out_dir=instance_diagnostics_<EXP_NAME> \
    test_evaluator.diagnostics.iou_thr=0.5 \
    test_evaluator.diagnostics.iou_lo_thr=0.1 \
    test_evaluator.diagnostics.gt_size_thr=100
```

单帧后处理旋钮统一用 `model.test_cfg.*` 覆盖（例如 `model.test_cfg.sp_score_thr=0.35`）。

---

# 5. 实验计划（分 Stage，每轮排除一个假设）

## Stage 0：Baseline 固化（必须先跑一遍）
**目的**：建立可对比的基线（并确认日志/输出路径无误）。

**改动**：无（只打开 diagnostics 且 out_dir 独立）。

**记录**：
- `gt_best_iou_0_0p5_rate_ge_100`
- `gt_hit_ge2_rate`
- `gt_hit_zero_rate_iou_lo_ge_100`
- `gt_best_iou_zero_rate_ge_100`
- `purity_low_rate / purity_high_rate`
- `pred_strong0_rate`（npz）

**预期**（参考你当前诊断的量级）：
- `gt_hit_ge2_rate` 高（~0.65）
- `gt_best_iou_0_0p5_rate_ge_100` 约 0.08 左右
- `gt_hit_zero_rate_iou_lo_ge_100` 极低（<1%）

---

## Stage 1：`sp_score_thr` sweep（定位“离散化/阈值吞边界”是否主因）
**假设 H1**：≥100 点大物体的 `0<iou<0.5` 主要由二值化阈值/离散化吞边界造成。

**对应代码位置**：二值化 `mask_pred = sigmoid(mask) > sp_score_thr`（`oneformer3d/mixformer3d.py:2121`）。

**改动**：只改 `model.test_cfg.sp_score_thr`，其余不动。

**扫参建议**：
- `sp_score_thr = 0.50, 0.45, 0.40, 0.35, 0.30, 0.25, 0.20`

**每次实验的 cfg-options 增量**（例）：
- `model.test_cfg.sp_score_thr=0.35`

**重点指标与判读**：
- 若 `gt_best_iou_0_0p5_rate_ge_100` 随阈值降低显著下降，且 `gt_hit_zero_rate_iou_lo_ge_100` 仍接近 0：
  - 支持 H1：主要是阈值/离散化问题。
- 若 `gt_best_iou_0_0p5_rate_ge_100` 基本不动：
  - 否定 H1：转入 Stage 2/3（预算/排序）。
- 监控副作用：
  - `purity_low_rate` 上升、`pred_strong0_rate` 上升、`gt_hit_ge2_rate` 上升 → 说明阈值变低“长胖”并引入噪声；后续必须配合更强去冗余/预算收紧才能用于 online。

**预期效果**：
- 成功情况下：≥100 点的 `0<iou<0.5` 比例下降（更多推过 0.5）
- 常见副作用：重复率上升、purity 下降

---

## Stage 2：候选预算 sweep（判断重复是否主要来自“尾部垃圾”）
Stage 2 只在 Stage 1 选定的“相对稳”的 `sp_score_thr` 下进行（例如 0.40 或 0.35）。

### Stage 2.1：只扫 `topk_insts`
**假设 H2**：重复主要来自 topK 尾部的低质/同质候选；收紧 topK 就能显著降重复且不伤 ≥100 弱命中。

**对应代码**：topK 选择（`oneformer3d/mixformer3d.py:2098`）。

**改动**：只改 `model.test_cfg.topk_insts`。

**扫参建议**：
- `topk_insts = 100 → 50 → 30 → 20`

**重点判读**：
- 若 `gt_hit_ge2_rate` 明显下降，且 `gt_hit_zero_rate_iou_lo_ge_100` 仍接近 0：
  - 支持 H2：重复主要在尾部，优先用预算收紧 + NMS（Stage 4）解决，未必需要显式 IoU clustering 去重。
- 若收紧 topK 导致 `gt_hit_zero_rate_iou_lo_ge_100` 上升：
  - 否定 H2：排序/score 校准有问题（你剪掉了“弱但有用”的候选），必须进入 Stage 3（排序偏好）或考虑后续“改 score/quality head”。

### Stage 2.2：只扫 `inst_score_thr`
**假设 H3**：重复主要来自低分尾部；提高 score 阈值能降重复且不伤 ≥100 弱命中。

**对应代码**：score filter（`oneformer3d/mixformer3d.py:2124`）。

**扫参建议**：
- `inst_score_thr = 0.00 → 0.05 → 0.10 → 0.20 → 0.25`

**判读与 Stage 2.1 类似**：
- 关注重复下降是否以牺牲 `gt_hit_zero_rate_iou_lo_ge_100` 为代价。

---

## Stage 3：排序偏好验证（`obj_normalization` on/off）
**假设 H4**：当前排序偏向“小而纯”（高 purity 低 coverage），使完整候选排不进 topK / 被压低，导致 ≥100 点仍有 8% 卡在 `0<iou<0.5`。

**对应代码**：`obj_normalization` 分支（`oneformer3d/mixformer3d.py:2109`）。

**改动**：只改 `model.test_cfg.obj_normalization=True/False`。

**固定**：使用 Stage 1/2 中你认为“在线友好”的一组阈值（例如 `sp=0.35, topk=50, inst_thr=0.05`）。

**重点判读**：
- 若关闭 `obj_normalization` 后 `gt_best_iou_0_0p5_rate_ge_100` 明显下降，但 `pred_strong0_rate` 上升 / `purity_low_rate` 上升 / 重复上升：
  - 强支持 H4：排序偏好确实在压制完整候选；后续应走“更好的 quality/score 校准”（例如新增 A2 或重训质量 head），而不是简单永久关闭 obj_norm。
- 若几乎无变化：
  - 弱化 H4：问题更可能在离散化或模型输出本身（转向 Stage 1 结论或重训方向）。

---

## Stage 4：现有 NMS 能力边界（`matrix_nms_kernel` 等）
**假设 H5**：现有 Matrix-NMS（仅 kernel）足以显著降重复；无需新增显式 de-dup clustering。

**对应代码**：`mask_matrix_nms(..., kernel=...)`（`oneformer3d/mixformer3d.py:2114`）。

**可做的最小 ablation（不改代码）**：
- `model.test_cfg.matrix_nms_kernel=linear` vs `gaussian`（如果支持）
- 同时固定 Stage 1–3 找到的最优组合

**重点判读**：
- 若 `gt_hit_ge2_rate` 显著下降且 `gt_hit_zero_rate_iou_lo_ge_100` 不上升：
  - 支持 H5：先把 NMS 调好，A1（显式去重）可后置。
- 若重复依旧顽固：
  - 否定 H5：说明重复来自“高分同质化”，现有 NMS 形态不足，下一步才考虑新增 A1（高 IoU 去重）或训练端去同质化。

---

## Stage 6：Rerank / quality-aware selection（前置到 topK）+ copy-suppress + fallback（最新主线）

该 Stage 以你们已完成的 “Oracle@K + best-IoU-rank” 硬证据为前提：
- topk=100 时 `oracle@100_ge100` 很高（好候选存在）
- 但 `best-rank_ge100` 长尾明显（好候选经常 rank 靠后）

因此本 Stage 的目标不是“创造候选”，而是：
1) **让好候选更靠前**（`best-rank_ge100` 前移，尤其 `>50` 比例下降）
2) **在不剪穿红线的前提下压重复**（`hit_ge2` 下降，且 `hit0@0.1_ge100 / best0_ge100` 不上升）

### Stage 6 的新增旋钮（代码已实现）

1) `model.test_cfg.selection`：quality-aware topK 选择（核心）
- `enable`：是否启用
- `mode`：`cls`（等价于原始 score） / `cls_stab_size`（推荐起步）
- `keep_topk`：主分数选出的保留数量（例如 50）
- `fallback_topk`：额外追加少量 `cls-only` 候选（用于“红线保底”），例如 10/20
- `stability_offset`：稳定性阈值偏移 Δ（默认 0.1），用 `IoU(thr-Δ, thr+Δ)` 的快速等价形式 `|hi|/|lo|`
- `gamma / delta`：稳定性与 size 纠偏的指数（推荐 `gamma=0.5~1.0`, `delta=0.2~0.4`）
- `size_ref / size_clip_min / size_clip_max`：size-aware 纠偏的参考尺度与 clip（避免“小而纯霸榜”）

2) `model.test_cfg.copy_suppress`：显式去重（会 drop mask）
- `enable`：是否启用
- `iou_thr`：认为“纯拷贝”的 IoU 阈值（推荐 0.9 或 0.85）
- `max_num`：最多保留实例数（例如 50）；若为 `None` 则只做“去拷贝不截断”
- `pre_max_num`：在做 pairwise IoU 前先按 score 取前 N 个，控制算力（可选，例如 80/100）

3) diagnostics：
- `test_evaluator.diagnostics.score_source=instance_select_scores`（强烈建议开启）

### Stage 6 最小实验矩阵（4 个点就能下结论）

所有实验建议固定：
- `sp_score_thr=0.45`, `inst_score_thr=0.0`, `obj_normalization=True`
- 候选池固定为 `model.test_cfg.topk_insts=100`（不改变“候选生成能力”）
- diagnostics 固定，且 `score_source=instance_select_scores`

#### (S6-0) Baseline 对照（你们已跑完，可不再重复）
- `topk_insts=100`，selection/copy_suppress 全关
- 作用：提供 `best-rank` 长尾与红线基线

#### (S6-1) Copy-suppress only：验证“只去拷贝”能把重复压到哪里（不改变选择信号）
- `selection.enable=False`
- `copy_suppress.enable=True, copy_suppress.iou_thr=0.9, copy_suppress.max_num=50`
- 预期：
  - `hit_ge2` 下降明显
  - 红线（`hit0@0.1_ge100 / best0_ge100`）基本不升
  - `best-rank` 不应大幅前移（因为选择信号没变）

#### (S6-2) Quality-topK only：验证 proxy 是否真的让好候选前移（不做去拷贝/不做保底）
- `selection.enable=True, selection.mode=cls_stab_size, selection.keep_topk=50, selection.fallback_topk=0`
- `copy_suppress.enable=False`
- 预期：
  - `best-rank_ge100` 明显前移（最硬证据）
  - 红线不应明显上升；若上升说明 proxy 偶发失效，需要 S6-3 的保底

#### (S6-3) Quality-topK + fallback：守红线（主排序 + recall 兜底）
- `selection.enable=True, selection.keep_topk=50, selection.fallback_topk=10/20`
- 预期：
  - `best-rank` 继续前移或保持
  - 红线更稳（`hit0@0.1_ge100` 不升甚至下降）
  - 重复可能回升一点（因为追加了候选），后续可再加 copy-suppress

#### (S6-4) Quality-topK + fallback + copy-suppress：目标形态（少而精且不剪穿）
- 在 S6-3 基础上再开 `copy_suppress`（建议先 0.9，再尝试 0.85）
- 预期：
  - `hit_ge2` 下降
  - 红线守住
  - 若这点成立，可作为后续 online 阶段的单帧供给策略候选

### Stage 6 的判读优先级（写死）
1) `best_iou_rank.ge_100.gt_50` / `p90/p95` 是否下降（是否真的“好候选前移”）
2) `miss_rates.gt_hit_zero_rate_iou_lo_ge_100` 与 `miss_rates.gt_best_iou_zero_rate_ge_100` 是否守住（online 红线）
3) `diagnosis.rates.gt_hit_ge2_rate` 是否下降（重复是否被压住）
4) `miss_rates.gt_best_iou_0_0p5_rate_ge_100` 是否下降（卡线是否有改善）
5) AP 仅作 sanity check（大幅下降通常意味着 proxy 把噪声顶上来了）

---

## Stage 7：RCS 补位式 Copy-Suppress（N→K，固定预算 K=50）

Stage 6 的主要结论之一是：**同帧重复会浪费 top slots**，但“只删不补位”会让 `pred_instances` 明显不足，从而红线/卡线变差。Stage 7 的目标是用更大的候选池 `N` 来补位，形成“固定预算 K=50 的多样候选”。

### Stage 7 固定设置（全程不变）
- `--cat-agnostic`
- `model.test_cfg.sp_score_thr=0.45`
- `model.test_cfg.inst_score_thr=0.0`（禁止用 score 强剪枝去重）
- `model.test_cfg.obj_normalization=True`
- `model.test_cfg.npoint_thr=100`
- diagnostics：`test_evaluator.diagnostics.score_source=instance_select_scores`

### Stage 7 核心方法（实现口径）
使用 `model.test_cfg.copy_suppress` 的 greedy 选择：
1) 候选池来自 `model.test_cfg.topk_insts=N`（增大 N 以提供补位空间）
2) 对过滤后的候选按 `copy_suppress.sort_by` 排序（建议默认用 `scores`，避免 cls-only 信号误选代表）
3) 依次扫描候选：若与已选任一 mask 的点域 IoU > `copy_suppress.iou_thr=τ` 则跳过，否则加入
4) 直到凑满 `copy_suppress.max_num=K` 或候选耗尽

注意：
- “补位”来自 **增大 N（topk_insts）**，而不是在 copy-suppress 内部额外回到更深层 query 重新生成候选。
- 为避免“排序信号不对齐”导致保留了低质代表，copy-suppress 支持 `prefer_by`（默认 `scores`）：当新候选与已选 mask IoU>τ 时，若 `prefer_by` 分数更高则替换已选代表（更鲁棒）。
- 若 `pred_instances` 显著小于 K，说明候选池（或过滤后有效候选）不足；优先增大 N，再考虑调 τ。

### Stage 7 主要观测指标（只看 ≥100 点桶 ge_100，优先级从高到低）
P0（红线，必须不升）：
- `hit0@0.1_ge100`：`miss_rates.gt_hit_zero_rate_iou_lo_ge_100`
- `best0_ge100`：`miss_rates.gt_best_iou_zero_rate_ge_100`

P1（重复，必须下降）：
- `hit_ge2`：`diagnosis.rates.gt_hit_ge2_rate`

P2（卡线，尽量不变或改善）：
- `best(0,0.5)_ge100`：`miss_rates.gt_best_iou_0_0p5_rate_ge_100`

辅助：
- `oracle@50_ge100`（top50 覆盖上界）
- `pred_instances`（是否接近每帧 50）
- `pred_strong0_rate`、`purity_low_rate`
- AP 仅 sanity（大幅下降=噪声被顶上来）

### Stage 7 最小实验点（先跑 E1/E2）

#### E1：RCS-100→50（核心验证）
- `topk_insts=100`
- `copy_suppress.enable=True`
- `copy_suppress.sort_by=scores`（建议）
- `copy_suppress.prefer_by=scores`（默认）
- `copy_suppress.allow_replace=True`（默认）
- `copy_suppress.refill=True`（默认）
- `copy_suppress.iou_thr=0.9`
- `copy_suppress.max_num=50`

判据：
- `hit_ge2` 明显低于 baseline(top100)
- 红线 `hit0@0.1_ge100 / best0_ge100` 不高于 baseline(top100)
- `pred_instances` 不应显著低于每帧 50（否则说明补位空间不足）

#### E2：RCS-200→50（池大小诊断）
- `topk_insts=200`（其余同 E1）

判据：
- 若 E2 相比 E1 明显改善红线/卡线，说明需要更大候选池做补位（在线可通过 `copy_suppress.pre_max_num` 控算力）
- 若 E2 仍守不住红线：再进入 τ 调整（例如 `τ=0.95`）来排查“误伤互补候选”

---

## Stage 5（可选）：小物体策略（`npoint_thr`）
该阶段不应影响主干结论（≥100 点）；只用于回答“是否要小物体”。

**对应代码**：`npoint_thr` filter（`oneformer3d/mixformer3d.py:2132`）。

**扫参建议**：
- `npoint_thr = 100 → 50 → 20`

**只看小桶指标**：
- `miss_rates.gt_hit_zero_rate_iou_lo_lt_100`
- `miss_rates.gt_best_iou_zero_rate_lt_100`
- 同时监控重复/噪声是否爆炸（`gt_hit_ge2_rate`, `pred_strong0_rate`）

---

# 6. 决策门槛：什么时候进入“新增逻辑 / 重训”

## 6.1 进入新增逻辑（A1/A2/A3）的条件（推理期改动不足）
当 Stage 1–4 无法同时满足：
- `gt_best_iou_0_0p5_rate_ge_100` 明显下降（质量变好）
- `gt_hit_ge2_rate` 明显下降（重复变少）
- `gt_hit_zero_rate_iou_lo_ge_100` 不上升（弱命中不被剪没）

且表现为：
- 重复主要来自高分同质化（NMS/预算无效）
- 或排序偏好明显（Stage 3 证实），但靠阈值/预算无法让“好候选”留在前列

则再考虑：
- A1：同帧高 IoU de-dup（压缩纯拷贝）
- A2：score re-calibration（更偏完整性，但需与去冗余绑定）
- A3：npoint_thr 策略化（小物体候选先保留，后续再确认）

## 6.2 进入重训（C1/C2/C3）的条件（需要从学习端修复）
满足任一条就说明推理旋钮难根治：
- Stage 1 显示 `sp_score_thr` 调整无法推动 `0<iou<0.5`（不是离散化）
- Stage 2 显示收紧预算会剪掉大量弱命中（排序/score 校准不足）
- Stage 3 显示排序偏好确实存在，但你缺少可靠质量分（当前 `objectness_flag=False`，`out['scores']` 很可能无效或缺失）

典型重训方向：
- 质量/IoU head（推理时替代/修正排序信号）
- 强化 non-object 惩罚、或增加去同质化（diversity）约束
- 调整 mask 损失以提升 coverage（减少保守）

---

# 7. 实验记录模板（强烈建议：每次实验一行）

建议用表格/CSV 记录（只要 4+2 个数字即可快速决策）：

| exp | sp_thr | topk | inst_thr | obj_norm | nms_kernel | best_0_0p5_ge100 | hit_ge2 | hit0_iou0p1_ge100 | best0_ge100 | purity_low | pred_strong0 |
|---|---:|---:|---:|---|---|---:|---:|---:|---:|---:|---:|

字段来源：
- JSON：`instance_diagnostics_<EXP>/instance_error_diagnostics.json`
- NPZ：`instance_diagnostics_<EXP>/instance_error_diagnostics_raw.npz`（`pred_strong0`）

---

# 8. 备注：单帧改善如何对齐在线重建（后续阶段）
本文件只做单帧。但每完成一个“单帧候选变少变精”的方案，建议抽样跑 online（MV config）做最小健康检查（不要求全量 mAP）：
- false birth / 每帧新生实例数
- 短命 track 比例
- 匹配抖动/ID switch

原因：单帧 AP 变好不保证 online 稳定；online 对候选冗余和排序不稳非常敏感。
