{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESAM 在线 DINOv2 数据增强与 2D–3D 对齐快速检查\n",
    "\n",
    "本 notebook 用于在 ESAM 环境下，对新引入的在线 DINOv2 + 数据增强管线做最小闭环验证：\n",
    "\n",
    "1. 从 `ESAM_sv_scannet200_CA_dino.py` 加载配置；\n",
    "2. 构建 ScanNet200-SV 训练数据集与 DataLoader，检查 `img` / `cam_info` / `points` 等字段；\n",
    "3. 构建 `ScanNet200MixFormer3D` 模型（包含 `DINOv2Backbone`），跑一次前向提取特征；\n",
    "4. 观察 DINO FPN 构建的日志与输出形状，确认 2D–3D 对齐链路工作正常。\n"
   ],
   "id": "c94ac9e1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e001892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD = /home/nebula/xxy/3D_Reconstruction\n",
      "sys.path[0] = /home/nebula/xxy/3D_Reconstruction\n"
     ]
    }
   ],
   "source": [
    "# 0. 环境与基础导入（在 ESAM conda/venv 环境下运行）\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.dataset import DefaultSampler, default_collate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mmdet3d.registry import MODELS, DATASETS\n",
    "from mmengine.runner import load_checkpoint\n",
    "\n",
    "# 显式将工作目录和 sys.path 切换到本地 3D_Reconstruction 根目录，\n",
    "# 确保优先使用本仓库的 oneformer3d 而不是可能安装在 site-packages 里的版本。\n",
    "repo_root = '/home/nebula/xxy/3D_Reconstruction'\n",
    "os.chdir(repo_root)\n",
    "# 去重后强制插到 sys.path[0]\n",
    "sys.path = [p for p in sys.path if p != repo_root]\n",
    "sys.path.insert(0, repo_root)\n",
    "print('CWD =', os.getcwd())\n",
    "print('sys.path[0] =', sys.path[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91013ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebula/miniconda3/envs/ESAM/lib/python3.8/site-packages/MinkowskiEngine-0.5.4-py3.8-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config from /home/nebula/xxy/3D_Reconstruction/configs/ESAM_CA/ESAM_sv_scannet200_CA_dino.py\n",
      "\n",
      "[train_pipeline]\n",
      "  LoadPointsFromFile {'type': 'LoadPointsFromFile', 'coord_type': 'DEPTH', 'shift_height': False, 'use_color': True, 'load_dim': 6, 'use_dim': [0, 1, 2, 3, 4, 5]}\n",
      "  LoadAnnotations3D_ {'type': 'LoadAnnotations3D_', 'with_bbox_3d': False, 'with_label_3d': False, 'with_mask_3d': True, 'with_seg_3d': True, 'with_sp_mask_3d': True}\n",
      "  SwapChairAndFloor {'type': 'SwapChairAndFloor'}\n",
      "  PointSegClassMapping {'type': 'PointSegClassMapping'}\n",
      "  LoadSingleImageFromFile {'type': 'LoadSingleImageFromFile', 'dataset_type': 'scannet200'}\n",
      "  RandomFlip3D {'type': 'RandomFlip3D', 'sync_2d': True, 'flip_ratio_bev_horizontal': 0.5, 'flip_ratio_bev_vertical': 0.0}\n",
      "  GlobalRotScaleTrans {'type': 'GlobalRotScaleTrans', 'rot_range': [-3.14, 3.14], 'scale_ratio_range': [0.8, 1.2], 'translation_std': [0.1, 0.1, 0.1], 'shift_height': False}\n",
      "  NormalizePointsColor_ {'type': 'NormalizePointsColor_', 'color_mean': (121.87247106275309, 109.73306679373762, 95.614771986258), 'color_std': (72.27912483750035, 70.2937017925937, 68.89837699573124)}\n",
      "  ColorJitterImg {'type': 'ColorJitterImg', 'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}\n",
      "  ResizeForDINO {'type': 'ResizeForDINO', 'target_size': (420, 560)}\n",
      "  AddSuperPointAnnotations {'type': 'AddSuperPointAnnotations', 'num_classes': 200, 'stuff_classes': [0, 1], 'merge_non_stuff_cls': False}\n",
      "  ElasticTransfrom {'type': 'ElasticTransfrom', 'gran': [6, 20], 'mag': [40, 160], 'voxel_size': 0.02, 'p': 0.5}\n",
      "  Pack3DDetInputs_ {'type': 'Pack3DDetInputs_', 'keys': ['points', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask', 'sp_pts_mask', 'gt_sp_masks', 'elastic_coords', 'img', 'cam_info']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebula/miniconda3/envs/ESAM/lib/python3.8/site-packages/mmdet3d/evaluation/functional/kitti_utils/eval.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def get_thresholds(scores: np.ndarray, num_gt, num_sample_pts=41):\n"
     ]
    }
   ],
   "source": [
    "# 1. 加载 ESAM DINO 配置（可在这里切换为 work_dirs 下的 ft 版本）\ncfg_path = os.path.join('configs', 'ESAM_CA', 'ESAM_sv_scannet200_CA_dino.py')\ncfg = Config.fromfile(cfg_path)\nprint('Loaded config from', os.path.abspath(cfg_path))\n\n# 简要查看 pipeline\nprint('\\n[train_pipeline]')\nfor t in cfg.train_dataloader.dataset.pipeline:\n    print(' ', t.get('type', 'Unknown'), t)\n\n\n# pipeline sanity checks\npipeline_types = [t.get('type', 'Unknown') for t in cfg.train_dataloader.dataset.pipeline if isinstance(t, dict)]\nprint('\n[pipeline sanity] contains BGR2RGBImg:', 'BGR2RGBImg' in pipeline_types)\nif 'BGR2RGBImg' in pipeline_types:\n    print('  BGR2RGBImg index:', pipeline_types.index('BGR2RGBImg'))\nprint('[pipeline sanity] contains ResizeForDINO:', 'ResizeForDINO' in pipeline_types)\nprint('[pipeline sanity] contains ColorJitterImg:', 'ColorJitterImg' in pipeline_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fbbcf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length = 10001\n",
      "[LoadCamInfo] 使用固定标准内参: [577.870605, 577.870605, 319.5, 239.5] (ScanNet官方策略)\n",
      "[Pack3DDetInputs_] keys=['points', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask', 'sp_pts_mask', 'gt_sp_masks', 'elastic_coords', 'img', 'cam_info'], inputs_keys=['points', 'elastic_coords', 'img', 'cam_info']\n",
      "[Pack3DDetInputs_] keys=['points', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask', 'sp_pts_mask', 'gt_sp_masks', 'elastic_coords', 'img', 'cam_info'], inputs_keys=['points', 'elastic_coords', 'img', 'cam_info']\n",
      "\n",
      "[Raw batch keys]: dict_keys(['data_samples', 'inputs'])\n",
      "[inputs keys]: dict_keys(['points', 'elastic_coords', 'img', 'cam_info'])\n",
      "batch_size = 2\n",
      "points type: <class 'torch.Tensor'> shape: torch.Size([2, 20000, 6])\n",
      "img type: <class 'torch.Tensor'> shape: torch.Size([2, 3, 420, 560])\n",
      "\n",
      "[cam_info raw]\n",
      "cam_info type: <class 'list'>\n",
      "cam_info len: 1\n",
      "[{'intrinsics': [tensor([505.6368, 505.6368], dtype=torch.float64), tensor([505.6368, 505.6368], dtype=torch.float64), tensor([279.5625, 279.5625], dtype=torch.float64), tensor([209.5625, 209.5625], dtype=torch.float64)], 'extrinsics': tensor([[[-0.2369,  0.4060, -0.8826,  1.6738],\n",
      "         [ 0.9647,  0.2060, -0.1642,  0.2581],\n",
      "         [ 0.1152, -0.8904, -0.4404,  0.8037],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[ 0.7942, -0.0192,  0.6074, -1.2304],\n",
      "         [-0.6032, -0.1460,  0.7841, -1.8067],\n",
      "         [ 0.0737, -0.9891, -0.1275,  0.2938],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]], dtype=torch.float64), 'pose': tensor([[[-0.2369,  0.4060, -0.8826,  1.6738],\n",
      "         [ 0.9647,  0.2060, -0.1642,  0.2581],\n",
      "         [ 0.1152, -0.8904, -0.4404,  0.8037],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[ 0.7942, -0.0192,  0.6074, -1.2304],\n",
      "         [-0.6032, -0.1460,  0.7841, -1.8067],\n",
      "         [ 0.0737, -0.9891, -0.1275,  0.2938],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]], dtype=torch.float64), 'img_size_dino': [tensor([420, 420]), tensor([560, 560])]}]\n",
      "\n",
      "[raw data_samples meta summary]\n",
      " sample 0: has_flow=True, flow=['R', 'S', 'T']\n",
      " sample 1: has_flow=True, flow=['HF', 'R', 'S', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebula/miniconda3/envs/ESAM/lib/python3.8/site-packages/mmdet3d/structures/points/base_points.py:136: UserWarning: point got color value beyond [0, 255]\n",
      "  warnings.warn('point got color value beyond [0, 255]')\n"
     ]
    }
   ],
   "source": [
    "# 2. 构建训练数据集与 DataLoader，并抓取一个 batch 做形状检查（支持 batch>1）\n",
    "train_dataset = DATASETS.build(cfg.train_dataloader.dataset)\n",
    "print('Train dataset length =', len(train_dataset))\n",
    "\n",
    "# 这里可以自由调大 batch_size 以测试 batch 对齐\n",
    "BATCH_SIZE = 2\n",
    "sampler = DefaultSampler(train_dataset, shuffle=False)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    collate_fn=default_collate,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print('\\n[Raw batch keys]:', batch.keys())\n",
    "inputs = batch['inputs']\n",
    "data_samples = batch['data_samples']\n",
    "print('[inputs keys]:', inputs.keys())\n",
    "print('batch_size =', BATCH_SIZE)\n",
    "\n",
    "# points: 可能是 list[Tensor] 或直接 Tensor（取决于 collate）\n",
    "pts_raw = inputs.get('points', None)\n",
    "if isinstance(pts_raw, list):\n",
    "    print('points list len:', len(pts_raw), 'first shape:', pts_raw[0].shape)\n",
    "else:\n",
    "    print('points type:', type(pts_raw), 'shape:', getattr(pts_raw, 'shape', None))\n",
    "\n",
    "# img: 通常会堆叠为 (B,3,420,560)\n",
    "img_raw = inputs.get('img', None)\n",
    "if img_raw is None:\n",
    "    print('img not found in inputs')\n",
    "else:\n",
    "    print('img type:', type(img_raw), 'shape:', getattr(img_raw, 'shape', None))\n",
    "\n",
    "# cam_info: raw 结构可能是 list[dict] 或被 batch 成单个 dict\n",
    "cam_raw = inputs.get('cam_info', None)\n",
    "print('\\n[cam_info raw]')\n",
    "print('cam_info type:', type(cam_raw))\n",
    "if isinstance(cam_raw, list):\n",
    "    print('cam_info len:', len(cam_raw))\n",
    "print(cam_raw)\n",
    "\n",
    "# raw data_samples 的 flow 预览（增强信息在 img_metas 中）\n",
    "print('\\n[raw data_samples meta summary]')\n",
    "for i, ds in enumerate(data_samples):\n",
    "    meta = getattr(ds, 'img_metas', None)\n",
    "    if not isinstance(meta, dict):\n",
    "        meta = ds.metainfo if hasattr(ds, 'metainfo') else {}\n",
    "    flow = meta.get('transformation_3d_flow', None)\n",
    "    print(f' sample {i}: has_flow={flow is not None}, flow={flow}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea9ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 16:34:15,462 - INFO - 从本地 DINOv2 repo 加载: /home/nebula/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebula/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/nebula/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:34: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/nebula/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "2025-12-12 16:34:15,467 - INFO - using MLP layer as FFN\n",
      "2025-12-12 16:34:17,746 - INFO - ✓ 从本地权重加载: /home/nebula/xxy/dataset/models/dinov2_vitl14_reg4_pretrain.pth\n",
      "2025-12-12 16:34:17,851 - INFO - ✓ 成功加载 dinov2_vitl14_reg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class: <class 'oneformer3d.mixformer3d.ScanNet200MixFormer3D'>\n",
      "Backbone: <class 'oneformer3d.mink_unet.Res16UNet34C'>\n",
      "DINO module: <class 'oneformer3d.dino_backbone.DINOv2Backbone'>\n",
      "Loading checkpoint from /home/nebula/xxy/3D_Reconstruction/work_dirs/ESAM_sv_scannet200_CA/best_all_ap_50%_epoch_128.pth\n",
      "Loads checkpoint by local backend from path: /home/nebula/xxy/3D_Reconstruction/work_dirs/ESAM_sv_scannet200_CA/best_all_ap_50%_epoch_128.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "missing keys in source state_dict: backbone.dino_proj_8.kernel, backbone.dino_proj_4.kernel, backbone.dino_proj_2.kernel, backbone.dino_proj_1.kernel, dino.model.cls_token, dino.model.pos_embed, dino.model.register_tokens, dino.model.mask_token, dino.model.patch_embed.proj.weight, dino.model.patch_embed.proj.bias, dino.model.blocks.0.norm1.weight, dino.model.blocks.0.norm1.bias, dino.model.blocks.0.attn.qkv.weight, dino.model.blocks.0.attn.qkv.bias, dino.model.blocks.0.attn.proj.weight, dino.model.blocks.0.attn.proj.bias, dino.model.blocks.0.ls1.gamma, dino.model.blocks.0.norm2.weight, dino.model.blocks.0.norm2.bias, dino.model.blocks.0.mlp.fc1.weight, dino.model.blocks.0.mlp.fc1.bias, dino.model.blocks.0.mlp.fc2.weight, dino.model.blocks.0.mlp.fc2.bias, dino.model.blocks.0.ls2.gamma, dino.model.blocks.1.norm1.weight, dino.model.blocks.1.norm1.bias, dino.model.blocks.1.attn.qkv.weight, dino.model.blocks.1.attn.qkv.bias, dino.model.blocks.1.attn.proj.weight, dino.model.blocks.1.attn.proj.bias, dino.model.blocks.1.ls1.gamma, dino.model.blocks.1.norm2.weight, dino.model.blocks.1.norm2.bias, dino.model.blocks.1.mlp.fc1.weight, dino.model.blocks.1.mlp.fc1.bias, dino.model.blocks.1.mlp.fc2.weight, dino.model.blocks.1.mlp.fc2.bias, dino.model.blocks.1.ls2.gamma, dino.model.blocks.2.norm1.weight, dino.model.blocks.2.norm1.bias, dino.model.blocks.2.attn.qkv.weight, dino.model.blocks.2.attn.qkv.bias, dino.model.blocks.2.attn.proj.weight, dino.model.blocks.2.attn.proj.bias, dino.model.blocks.2.ls1.gamma, dino.model.blocks.2.norm2.weight, dino.model.blocks.2.norm2.bias, dino.model.blocks.2.mlp.fc1.weight, dino.model.blocks.2.mlp.fc1.bias, dino.model.blocks.2.mlp.fc2.weight, dino.model.blocks.2.mlp.fc2.bias, dino.model.blocks.2.ls2.gamma, dino.model.blocks.3.norm1.weight, dino.model.blocks.3.norm1.bias, dino.model.blocks.3.attn.qkv.weight, dino.model.blocks.3.attn.qkv.bias, dino.model.blocks.3.attn.proj.weight, dino.model.blocks.3.attn.proj.bias, dino.model.blocks.3.ls1.gamma, dino.model.blocks.3.norm2.weight, dino.model.blocks.3.norm2.bias, dino.model.blocks.3.mlp.fc1.weight, dino.model.blocks.3.mlp.fc1.bias, dino.model.blocks.3.mlp.fc2.weight, dino.model.blocks.3.mlp.fc2.bias, dino.model.blocks.3.ls2.gamma, dino.model.blocks.4.norm1.weight, dino.model.blocks.4.norm1.bias, dino.model.blocks.4.attn.qkv.weight, dino.model.blocks.4.attn.qkv.bias, dino.model.blocks.4.attn.proj.weight, dino.model.blocks.4.attn.proj.bias, dino.model.blocks.4.ls1.gamma, dino.model.blocks.4.norm2.weight, dino.model.blocks.4.norm2.bias, dino.model.blocks.4.mlp.fc1.weight, dino.model.blocks.4.mlp.fc1.bias, dino.model.blocks.4.mlp.fc2.weight, dino.model.blocks.4.mlp.fc2.bias, dino.model.blocks.4.ls2.gamma, dino.model.blocks.5.norm1.weight, dino.model.blocks.5.norm1.bias, dino.model.blocks.5.attn.qkv.weight, dino.model.blocks.5.attn.qkv.bias, dino.model.blocks.5.attn.proj.weight, dino.model.blocks.5.attn.proj.bias, dino.model.blocks.5.ls1.gamma, dino.model.blocks.5.norm2.weight, dino.model.blocks.5.norm2.bias, dino.model.blocks.5.mlp.fc1.weight, dino.model.blocks.5.mlp.fc1.bias, dino.model.blocks.5.mlp.fc2.weight, dino.model.blocks.5.mlp.fc2.bias, dino.model.blocks.5.ls2.gamma, dino.model.blocks.6.norm1.weight, dino.model.blocks.6.norm1.bias, dino.model.blocks.6.attn.qkv.weight, dino.model.blocks.6.attn.qkv.bias, dino.model.blocks.6.attn.proj.weight, dino.model.blocks.6.attn.proj.bias, dino.model.blocks.6.ls1.gamma, dino.model.blocks.6.norm2.weight, dino.model.blocks.6.norm2.bias, dino.model.blocks.6.mlp.fc1.weight, dino.model.blocks.6.mlp.fc1.bias, dino.model.blocks.6.mlp.fc2.weight, dino.model.blocks.6.mlp.fc2.bias, dino.model.blocks.6.ls2.gamma, dino.model.blocks.7.norm1.weight, dino.model.blocks.7.norm1.bias, dino.model.blocks.7.attn.qkv.weight, dino.model.blocks.7.attn.qkv.bias, dino.model.blocks.7.attn.proj.weight, dino.model.blocks.7.attn.proj.bias, dino.model.blocks.7.ls1.gamma, dino.model.blocks.7.norm2.weight, dino.model.blocks.7.norm2.bias, dino.model.blocks.7.mlp.fc1.weight, dino.model.blocks.7.mlp.fc1.bias, dino.model.blocks.7.mlp.fc2.weight, dino.model.blocks.7.mlp.fc2.bias, dino.model.blocks.7.ls2.gamma, dino.model.blocks.8.norm1.weight, dino.model.blocks.8.norm1.bias, dino.model.blocks.8.attn.qkv.weight, dino.model.blocks.8.attn.qkv.bias, dino.model.blocks.8.attn.proj.weight, dino.model.blocks.8.attn.proj.bias, dino.model.blocks.8.ls1.gamma, dino.model.blocks.8.norm2.weight, dino.model.blocks.8.norm2.bias, dino.model.blocks.8.mlp.fc1.weight, dino.model.blocks.8.mlp.fc1.bias, dino.model.blocks.8.mlp.fc2.weight, dino.model.blocks.8.mlp.fc2.bias, dino.model.blocks.8.ls2.gamma, dino.model.blocks.9.norm1.weight, dino.model.blocks.9.norm1.bias, dino.model.blocks.9.attn.qkv.weight, dino.model.blocks.9.attn.qkv.bias, dino.model.blocks.9.attn.proj.weight, dino.model.blocks.9.attn.proj.bias, dino.model.blocks.9.ls1.gamma, dino.model.blocks.9.norm2.weight, dino.model.blocks.9.norm2.bias, dino.model.blocks.9.mlp.fc1.weight, dino.model.blocks.9.mlp.fc1.bias, dino.model.blocks.9.mlp.fc2.weight, dino.model.blocks.9.mlp.fc2.bias, dino.model.blocks.9.ls2.gamma, dino.model.blocks.10.norm1.weight, dino.model.blocks.10.norm1.bias, dino.model.blocks.10.attn.qkv.weight, dino.model.blocks.10.attn.qkv.bias, dino.model.blocks.10.attn.proj.weight, dino.model.blocks.10.attn.proj.bias, dino.model.blocks.10.ls1.gamma, dino.model.blocks.10.norm2.weight, dino.model.blocks.10.norm2.bias, dino.model.blocks.10.mlp.fc1.weight, dino.model.blocks.10.mlp.fc1.bias, dino.model.blocks.10.mlp.fc2.weight, dino.model.blocks.10.mlp.fc2.bias, dino.model.blocks.10.ls2.gamma, dino.model.blocks.11.norm1.weight, dino.model.blocks.11.norm1.bias, dino.model.blocks.11.attn.qkv.weight, dino.model.blocks.11.attn.qkv.bias, dino.model.blocks.11.attn.proj.weight, dino.model.blocks.11.attn.proj.bias, dino.model.blocks.11.ls1.gamma, dino.model.blocks.11.norm2.weight, dino.model.blocks.11.norm2.bias, dino.model.blocks.11.mlp.fc1.weight, dino.model.blocks.11.mlp.fc1.bias, dino.model.blocks.11.mlp.fc2.weight, dino.model.blocks.11.mlp.fc2.bias, dino.model.blocks.11.ls2.gamma, dino.model.blocks.12.norm1.weight, dino.model.blocks.12.norm1.bias, dino.model.blocks.12.attn.qkv.weight, dino.model.blocks.12.attn.qkv.bias, dino.model.blocks.12.attn.proj.weight, dino.model.blocks.12.attn.proj.bias, dino.model.blocks.12.ls1.gamma, dino.model.blocks.12.norm2.weight, dino.model.blocks.12.norm2.bias, dino.model.blocks.12.mlp.fc1.weight, dino.model.blocks.12.mlp.fc1.bias, dino.model.blocks.12.mlp.fc2.weight, dino.model.blocks.12.mlp.fc2.bias, dino.model.blocks.12.ls2.gamma, dino.model.blocks.13.norm1.weight, dino.model.blocks.13.norm1.bias, dino.model.blocks.13.attn.qkv.weight, dino.model.blocks.13.attn.qkv.bias, dino.model.blocks.13.attn.proj.weight, dino.model.blocks.13.attn.proj.bias, dino.model.blocks.13.ls1.gamma, dino.model.blocks.13.norm2.weight, dino.model.blocks.13.norm2.bias, dino.model.blocks.13.mlp.fc1.weight, dino.model.blocks.13.mlp.fc1.bias, dino.model.blocks.13.mlp.fc2.weight, dino.model.blocks.13.mlp.fc2.bias, dino.model.blocks.13.ls2.gamma, dino.model.blocks.14.norm1.weight, dino.model.blocks.14.norm1.bias, dino.model.blocks.14.attn.qkv.weight, dino.model.blocks.14.attn.qkv.bias, dino.model.blocks.14.attn.proj.weight, dino.model.blocks.14.attn.proj.bias, dino.model.blocks.14.ls1.gamma, dino.model.blocks.14.norm2.weight, dino.model.blocks.14.norm2.bias, dino.model.blocks.14.mlp.fc1.weight, dino.model.blocks.14.mlp.fc1.bias, dino.model.blocks.14.mlp.fc2.weight, dino.model.blocks.14.mlp.fc2.bias, dino.model.blocks.14.ls2.gamma, dino.model.blocks.15.norm1.weight, dino.model.blocks.15.norm1.bias, dino.model.blocks.15.attn.qkv.weight, dino.model.blocks.15.attn.qkv.bias, dino.model.blocks.15.attn.proj.weight, dino.model.blocks.15.attn.proj.bias, dino.model.blocks.15.ls1.gamma, dino.model.blocks.15.norm2.weight, dino.model.blocks.15.norm2.bias, dino.model.blocks.15.mlp.fc1.weight, dino.model.blocks.15.mlp.fc1.bias, dino.model.blocks.15.mlp.fc2.weight, dino.model.blocks.15.mlp.fc2.bias, dino.model.blocks.15.ls2.gamma, dino.model.blocks.16.norm1.weight, dino.model.blocks.16.norm1.bias, dino.model.blocks.16.attn.qkv.weight, dino.model.blocks.16.attn.qkv.bias, dino.model.blocks.16.attn.proj.weight, dino.model.blocks.16.attn.proj.bias, dino.model.blocks.16.ls1.gamma, dino.model.blocks.16.norm2.weight, dino.model.blocks.16.norm2.bias, dino.model.blocks.16.mlp.fc1.weight, dino.model.blocks.16.mlp.fc1.bias, dino.model.blocks.16.mlp.fc2.weight, dino.model.blocks.16.mlp.fc2.bias, dino.model.blocks.16.ls2.gamma, dino.model.blocks.17.norm1.weight, dino.model.blocks.17.norm1.bias, dino.model.blocks.17.attn.qkv.weight, dino.model.blocks.17.attn.qkv.bias, dino.model.blocks.17.attn.proj.weight, dino.model.blocks.17.attn.proj.bias, dino.model.blocks.17.ls1.gamma, dino.model.blocks.17.norm2.weight, dino.model.blocks.17.norm2.bias, dino.model.blocks.17.mlp.fc1.weight, dino.model.blocks.17.mlp.fc1.bias, dino.model.blocks.17.mlp.fc2.weight, dino.model.blocks.17.mlp.fc2.bias, dino.model.blocks.17.ls2.gamma, dino.model.blocks.18.norm1.weight, dino.model.blocks.18.norm1.bias, dino.model.blocks.18.attn.qkv.weight, dino.model.blocks.18.attn.qkv.bias, dino.model.blocks.18.attn.proj.weight, dino.model.blocks.18.attn.proj.bias, dino.model.blocks.18.ls1.gamma, dino.model.blocks.18.norm2.weight, dino.model.blocks.18.norm2.bias, dino.model.blocks.18.mlp.fc1.weight, dino.model.blocks.18.mlp.fc1.bias, dino.model.blocks.18.mlp.fc2.weight, dino.model.blocks.18.mlp.fc2.bias, dino.model.blocks.18.ls2.gamma, dino.model.blocks.19.norm1.weight, dino.model.blocks.19.norm1.bias, dino.model.blocks.19.attn.qkv.weight, dino.model.blocks.19.attn.qkv.bias, dino.model.blocks.19.attn.proj.weight, dino.model.blocks.19.attn.proj.bias, dino.model.blocks.19.ls1.gamma, dino.model.blocks.19.norm2.weight, dino.model.blocks.19.norm2.bias, dino.model.blocks.19.mlp.fc1.weight, dino.model.blocks.19.mlp.fc1.bias, dino.model.blocks.19.mlp.fc2.weight, dino.model.blocks.19.mlp.fc2.bias, dino.model.blocks.19.ls2.gamma, dino.model.blocks.20.norm1.weight, dino.model.blocks.20.norm1.bias, dino.model.blocks.20.attn.qkv.weight, dino.model.blocks.20.attn.qkv.bias, dino.model.blocks.20.attn.proj.weight, dino.model.blocks.20.attn.proj.bias, dino.model.blocks.20.ls1.gamma, dino.model.blocks.20.norm2.weight, dino.model.blocks.20.norm2.bias, dino.model.blocks.20.mlp.fc1.weight, dino.model.blocks.20.mlp.fc1.bias, dino.model.blocks.20.mlp.fc2.weight, dino.model.blocks.20.mlp.fc2.bias, dino.model.blocks.20.ls2.gamma, dino.model.blocks.21.norm1.weight, dino.model.blocks.21.norm1.bias, dino.model.blocks.21.attn.qkv.weight, dino.model.blocks.21.attn.qkv.bias, dino.model.blocks.21.attn.proj.weight, dino.model.blocks.21.attn.proj.bias, dino.model.blocks.21.ls1.gamma, dino.model.blocks.21.norm2.weight, dino.model.blocks.21.norm2.bias, dino.model.blocks.21.mlp.fc1.weight, dino.model.blocks.21.mlp.fc1.bias, dino.model.blocks.21.mlp.fc2.weight, dino.model.blocks.21.mlp.fc2.bias, dino.model.blocks.21.ls2.gamma, dino.model.blocks.22.norm1.weight, dino.model.blocks.22.norm1.bias, dino.model.blocks.22.attn.qkv.weight, dino.model.blocks.22.attn.qkv.bias, dino.model.blocks.22.attn.proj.weight, dino.model.blocks.22.attn.proj.bias, dino.model.blocks.22.ls1.gamma, dino.model.blocks.22.norm2.weight, dino.model.blocks.22.norm2.bias, dino.model.blocks.22.mlp.fc1.weight, dino.model.blocks.22.mlp.fc1.bias, dino.model.blocks.22.mlp.fc2.weight, dino.model.blocks.22.mlp.fc2.bias, dino.model.blocks.22.ls2.gamma, dino.model.blocks.23.norm1.weight, dino.model.blocks.23.norm1.bias, dino.model.blocks.23.attn.qkv.weight, dino.model.blocks.23.attn.qkv.bias, dino.model.blocks.23.attn.proj.weight, dino.model.blocks.23.attn.proj.bias, dino.model.blocks.23.ls1.gamma, dino.model.blocks.23.norm2.weight, dino.model.blocks.23.norm2.bias, dino.model.blocks.23.mlp.fc1.weight, dino.model.blocks.23.mlp.fc1.bias, dino.model.blocks.23.mlp.fc2.weight, dino.model.blocks.23.mlp.fc2.bias, dino.model.blocks.23.ls2.gamma, dino.model.norm.weight, dino.model.norm.bias\n",
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 3. 构建 ScanNet200MixFormer3D 模型并加载预训练权重（如果 cfg.load_from 存在）\nmodel = MODELS.build(cfg.model)\nprint('Model class:', type(model))\nprint('Backbone:', type(model.backbone))\nif hasattr(model, 'dino'):\n    print('DINO module:', type(model.dino))\nelse:\n    print('No DINO module found on model')\n\nimport inspect\nimport oneformer3d.mixformer3d as mixformer3d_mod\nprint('oneformer3d.mixformer3d file =', mixformer3d_mod.__file__)\nprint('signature _build_dino_fpn_online:', inspect.signature(model._build_dino_fpn_online))\n\nif cfg.get('load_from', None) is not None:\n    ckpt_path = cfg.load_from\n    print('Loading checkpoint from', ckpt_path)\n    _ = load_checkpoint(model, ckpt_path, map_location='cpu')\nelse:\n    print('cfg.load_from is None, using randomly initialized weights')\n\n# 移动到 GPU（如果可用）\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\nmodel.eval()\nprint('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e828b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After data_preprocessor] inputs keys: dict_keys(['points', 'elastic_coords', 'img', 'cam_info'])\n",
      "  img tensor shape: torch.Size([2, 3, 420, 560]) device: cuda:0\n",
      "  cam_info type: <class 'list'> len: 1\n",
      "\n",
      "[3D aug flow per sample]\n",
      " sample 0: flow=['R', 'S', 'T'], hits={'HF': False, 'R': True, 'S': True, 'T': True, 'VF': False}, hflip=False, rot_angle=0.30148888902291926, scale=1.1061340855918897, trans=[    0.13457     0.11183   -0.017188]\n",
      " sample 1: flow=['HF', 'R', 'S', 'T'], hits={'HF': True, 'R': True, 'S': True, 'T': True, 'VF': False}, hflip=True, rot_angle=1.676274561710661, scale=1.002212835630251, trans=[   0.020099  0.00077867   -0.013422]\n",
      "using device for forward: cuda:0\n",
      "[DINO][debug] keys={'dino_fpn': False, 'dino_feats': False, 'dino_point_feats': False, 'clip_pix': False, 'img': True, 'cam_info': True}, cam_info_type=<class 'list'>, cam_len=1\n",
      "[DINO] build from online DINO backbone, shapes=[torch.Size([23351, 1024]), torch.Size([9744, 1024]), torch.Size([2919, 1024]), torch.Size([824, 1024]), torch.Size([227, 1024])], strides=[[1, 1, 1], [2, 2, 2], [4, 4, 4], [8, 8, 8], [16, 16, 16]]\n",
      "\n",
      "[extract_feat outputs]\n",
      "  #superpoint feature tensors: 2\n",
      "  first sp_feat shape: torch.Size([118, 96])\n",
      "  #point feature tensors: 2\n",
      "  first point_feat shape: torch.Size([20000, 99])\n",
      "  all_xyz_w shape: torch.Size([40000, 1])\n",
      "\n",
      "[DINO debug] last DINO feat shape (B,C,H_p,W_p): torch.Size([2, 1024, 30, 40])\n",
      "[DINO debug] valid_rate (all points): 1.0000\n",
      "  per-sample valid rates: ['1.0000', '1.0000']\n",
      "\n",
      "如果上述 cell 没有报错，并能看到 [DINO] 日志、DINO 特征图尺寸与合理的 valid rate，则在线 DINO + 2D–3D 对齐路径基本工作正常。\n"
     ]
    }
   ],
   "source": [
    "# 4. 通过 Det3DDataPreprocessor_ 处理 batch，然后调用 extract_feat，检查 DINO FPN（支持 batch>1）\nwith torch.no_grad():\n    # data_preprocessor 期望的输入是 dict，已经包含 'inputs' 与 'data_samples'\n    data_batch = {'inputs': batch['inputs'], 'data_samples': batch['data_samples']}\n    processed = model.data_preprocessor(data_batch, training=False)\n    batch_inputs = processed['inputs']\n    batch_samples = processed['data_samples']\n\n    print('[After data_preprocessor] inputs keys:', batch_inputs.keys())\n    if 'img' in batch_inputs:\n        print('  img tensor shape:', batch_inputs['img'].shape, 'device:', batch_inputs['img'].device)\n    if 'cam_info' in batch_inputs:\n        cam_raw = batch_inputs['cam_info']\n        print('  cam_info type:', type(cam_raw), 'len:', len(cam_raw) if isinstance(cam_raw, list) else None)\n\n    # ---- 统一搬运到 model device，避免 CPU/GPU 混用 ----\n    device = next(model.parameters()).device\n    def _to_dev(x):\n        return x.to(device) if torch.is_tensor(x) else x\n\n    pts = batch_inputs.get('points', None)\n    if isinstance(pts, list):\n        batch_inputs['points'] = [p.to(device) for p in pts]\n    elif torch.is_tensor(pts):\n        batch_inputs['points'] = pts.to(device)\n\n    if 'img' in batch_inputs and torch.is_tensor(batch_inputs['img']):\n        batch_inputs['img'] = batch_inputs['img'].to(device)\n\n    if 'elastic_coords' in batch_inputs:\n        ec = batch_inputs['elastic_coords']\n        if isinstance(ec, list):\n            new_ec = []\n            for e in ec:\n                if torch.is_tensor(e):\n                    new_ec.append(e.to(device))\n                else:\n                    new_ec.append(torch.as_tensor(e, device=device, dtype=torch.float32))\n            batch_inputs['elastic_coords'] = new_ec\n        else:\n            batch_inputs['elastic_coords'] = torch.as_tensor(ec, device=device, dtype=torch.float32)\n\n    for k in ['clip_pix', 'clip_global', 'dino_point_feats']:\n        if k in batch_inputs:\n            v = batch_inputs[k]\n            if isinstance(v, list):\n                batch_inputs[k] = [_to_dev(t) for t in v]\n            elif torch.is_tensor(v):\n                batch_inputs[k] = v.to(device)\n\n    # ---- 打印每个样本的 3D 增强命中情况（HF/R/S/T） ----\n    print('\\n[3D aug flow per sample]')\n    for i, sample in enumerate(batch_samples):\n        meta = getattr(sample, 'img_metas', None)\n        if not isinstance(meta, dict):\n            meta = sample.metainfo if hasattr(sample, 'metainfo') else {}\n        flow = meta.get('transformation_3d_flow', []) or []\n        hits = {k: (k in flow) for k in ['HF', 'R', 'S', 'T', 'VF']}\n        print(\n            f' sample {i}: flow={flow}, hits={hits}, '\n            f'hflip={meta.get(\"pcd_horizontal_flip\")}, '\n            f'rot_angle={meta.get(\"pcd_rotation_angle\")}, '\n            f'scale={meta.get(\"pcd_scale_factor\")}, '\n            f'trans={meta.get(\"pcd_trans\")}'\n        )\n    print('using device for forward:', device)\n\n    # 调用 extract_feat，内部会触发在线 DINO + FPN 构建\n    features, point_features, all_xyz_w = model.extract_feat(batch_inputs, batch_samples)\n    print('\\n[extract_feat outputs]')\n    print('  #superpoint feature tensors:', len(features))\n    print('  first sp_feat shape:', features[0].shape if len(features) > 0 else None)\n    print('  #point feature tensors:', len(point_features))\n    print('  first point_feat shape:', point_features[0].shape if len(point_features) > 0 else None)\n    print('  all_xyz_w shape:', all_xyz_w.shape if hasattr(all_xyz_w, 'shape') else type(all_xyz_w))\n\n    # 额外输出：DINO 特征图尺寸与 2D–3D valid rate\n    if getattr(model, 'dino', None) is not None:\n        last_shape = getattr(model.dino, '_last_feat_shape', None)\n        if last_shape is not None:\n            print('\\n[DINO debug] last DINO feat shape (B,C,H_p,W_p):', last_shape)\n\n    valid_rate = getattr(model, '_last_dino_valid_rate', None)\n    per_sample = getattr(model, '_last_dino_valid_rate_per_sample', None)\n    if valid_rate is not None:\n        print('[DINO debug] valid_rate (all points): {:.4f}'.format(valid_rate))\n        if isinstance(per_sample, (list, tuple)):\n            print('  per-sample valid rates:', ['{:.4f}'.format(r) for r in per_sample])\n    else:\n        print('[DINO debug] valid_rate not available')\n\n    coords_src = getattr(model, '_last_dino_coords_source', None)\n    if coords_src is not None:\n        print('[DINO debug] dino coords source (per-sample):', coords_src)\n    else:\n        print('[DINO debug] dino coords source not available')\n\n\nprint('\\n如果上述 cell 没有报错，并能看到 [DINO] 日志、DINO 特征图尺寸与合理的 valid rate，则在线 DINO + 2D–3D 对齐路径基本工作正常。')\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}