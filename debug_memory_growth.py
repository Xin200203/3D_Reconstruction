#!/usr/bin/env python3

import sys
import os
sys.path.append('/home/nebula/xxy/ESAM')
os.chdir('/home/nebula/xxy/ESAM')

import torch
import subprocess
import time
from mmengine import Config

def monitor_model_memory():
    """åˆ†ææ¨¡å‹æ˜¾å­˜ä½¿ç”¨çš„å¢é•¿æ¨¡å¼"""
    
    print("=== BiFusionæ¨¡å‹æ˜¾å­˜å¢é•¿åˆ†æ ===")
    
    # æ¸…ç©ºæ˜¾å­˜
    torch.cuda.empty_cache()
    initial_memory = torch.cuda.memory_allocated() / 1024**3
    print(f"åˆå§‹æ˜¾å­˜ä½¿ç”¨: {initial_memory:.2f} GB")
    
    try:
        # åŠ è½½é…ç½®
        cfg = Config.fromfile('configs/ESAM_CA/sv_bifusion_scannet200.py')
        print("âœ“ é…ç½®åŠ è½½æˆåŠŸ")
        
        # æ¨¡æ‹Ÿä¸åŒå‚æ•°ç»„çš„æ˜¾å­˜å ç”¨
        param_groups = {
            'CLIP_conv1': 590592,          # CLIP conv1å±‚å‚æ•°
            'CLIP_transformer': 87084032,  # CLIP transformerå‚æ•° 
            'backbone3d': 16777216,        # 3D backboneå‚æ•°
            'decoder': 33554432,           # è§£ç å™¨å‚æ•°
        }
        
        print("\næ¨¡æ‹Ÿä¼˜åŒ–å™¨çŠ¶æ€åˆ›å»ºè¿‡ç¨‹:")
        cumulative_memory = initial_memory
        
        for epoch in range(1, 12):
            print(f"\nEpoch {epoch}:")
            
            # æ¨¡æ‹Ÿä¸åŒepochä¸‹å‚æ•°çš„æ¿€æ´»
            active_groups = []
            if epoch >= 1:
                active_groups.extend(['backbone3d', 'decoder'])
            if epoch >= 3:  # CLIPå¯èƒ½åœ¨ç¬¬3ä¸ªepochåå¼€å§‹è§£å†»
                active_groups.append('CLIP_conv1')
            if epoch >= 6:  # æ›´å¤šCLIPå±‚è§£å†»
                active_groups.append('CLIP_transformer')
            
            # è®¡ç®—å½“å‰epochçš„ä¼˜åŒ–å™¨çŠ¶æ€å†…å­˜éœ€æ±‚
            optimizer_memory = 0
            for group in active_groups:
                param_count = param_groups[group]
                # AdamWéœ€è¦2ä¸ªçŠ¶æ€ï¼šmomentum + variance
                state_memory = param_count * 4 * 2 / 1024**3  # float32 * 2çŠ¶æ€
                optimizer_memory += state_memory
                
            total_memory = initial_memory + optimizer_memory
            print(f"  æ¿€æ´»å‚æ•°ç»„: {active_groups}")
            print(f"  ä¼˜åŒ–å™¨çŠ¶æ€æ˜¾å­˜: {optimizer_memory:.2f} GB")
            print(f"  æ€»æ˜¾å­˜é¢„ä¼°: {total_memory:.2f} GB")
            
            if total_memory > 22.0:  # RTX 4090çº¦22GBå¯ç”¨
                print(f"  âš ï¸ æ˜¾å­˜ä¸è¶³ï¼å¯èƒ½åœ¨Epoch {epoch}è§¦å‘OOM")
                break
                
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")

def check_checkpoint_compatibility():
    """æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹çš„å…¼å®¹æ€§"""
    print("\n=== é¢„è®­ç»ƒæ¨¡å‹å…¼å®¹æ€§æ£€æŸ¥ ===")
    
    checkpoint_path = '/home/nebula/xxy/ESAM/work_dirs/sv3d_scannet200_ca/best_all_ap_50%_epoch_128.pth'
    
    if not os.path.exists(checkpoint_path):
        print(f"âš ï¸ é¢„è®­ç»ƒæ¨¡å‹ä¸å­˜åœ¨: {checkpoint_path}")
        return
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            
            # åˆ†æé¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°
            clip_params = [k for k in state_dict.keys() if 'clip' in k.lower() or 'enhanced_clip' in k]
            fusion_params = [k for k in state_dict.keys() if 'bi_encoder' in k or 'fusion' in k]
            
            print(f"é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ç»Ÿè®¡:")
            print(f"  æ€»å‚æ•°: {len(state_dict)}")
            print(f"  CLIPç›¸å…³å‚æ•°: {len(clip_params)}")
            print(f"  Fusionç›¸å…³å‚æ•°: {len(fusion_params)}")
            
            if len(clip_params) == 0:
                print("  âš ï¸ é¢„è®­ç»ƒæ¨¡å‹ç¼ºå°‘CLIPå‚æ•° - è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆåæœŸæ‰OOMï¼")
                print("  ğŸ’¡ CLIPå‚æ•°éœ€è¦æ–°åˆå§‹åŒ–ï¼Œä¼˜åŒ–å™¨çŠ¶æ€ä¼šåœ¨åæœŸåˆ›å»º")
            
    except Exception as e:
        print(f"æ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    monitor_model_memory()
    check_checkpoint_compatibility() 