下面按照「是谁算的 → 需要哪些张量 → 步骤 → 数学公式 → 名词解释」的格式，把 ESAM 里用到的几种损失逐一拆开。为了易读，先给出常用记号：

• \(N\)：当前 sample 中点的总个数（SV 是单帧 2 万，MV 是 \(V\!\times\!2 万\)）  
• \(Q\)：查询 query 的个数（默认 128）  
• \(C\)：语义类别数（ScanNet200 则 \(C=200\)）  
• \({\bf 1}[\cdot]\)：指示函数，条件成立取 1，否则 0  
• \(\langle\cdot,\cdot\rangle\)：向量或张量按元素相乘再求和  
• \(\|x\|_1 / \|x\|_2\)：L1 / L2 范数  
（公式只写核心部分，批次维 \(\mathit{B}\) 默认求平均）

────────────────────────────  
1. 语义分割损失 L_sem  
────────────────────────────  
【模块】`ScanNetSemanticCriterion`  
【输入】  
  • 预测：`semantic_logits ∈ ℝ^{N×C}` —— 每点对每个类别给出分数  
  • GT：`pts_semantic_mask ∈ {0,…,C}` —— 每点真实类别  
【步骤】  
 1) Softmax → 概率 \(p_{ic}\)  
 2) 交叉熵  
   \[
     L_{\text{sem}} = -\frac1N \sum_{i=1}^{N}\sum_{c=1}^{C}  
        {\bf 1}[y_i=c] \log p_{ic}
   \]
【理解】像普通图像分割 CE，只是把“像素”换成“点”。

────────────────────────────  
2. 实例分割损失 L_inst  
────────────────────────────  
【模块】`InstanceCriterion`（或 `MixedInstanceCriterion` 带 BBox）  
【核心思路】先用匈牙利算法把 **查询 Q** 与 **GT 实例** 配对，再计算四项子损失。  

–––– 2.1 匈牙利匹配 ––––  
【参与张量】  
  • `query_masks_sigmoid  q_j ∈ [0,1]^{N}` —— 第 j 个查询对每点的概率  
  • `gt_sp_masks         g_k ∈ {0,1}^{N}` —— 第 k 个实例在超像素层的分布  
  • `query_cls_logits    c_j ∈ ℝ^{C+1}` – C类 + “背景”  
【代价】  
 1) 分类代价  
    \(d_{\text{cls}}(j,k) = 1 - \text{softmax}(c_j)[\text{label}_k]\)  
 2) 掩码 BCE  
    \(d_{\text{bce}}(j,k)=\frac1N\langle q_j, 1-g_k\rangle + \langle1-q_j,g_k\rangle\)  
 3) 掩码 Dice  
    \(d_{\text{dice}}(j,k)=1-\frac{2\langle q_j,g_k\rangle}{\langle q_j,q_j\rangle+\langle g_k,g_k\rangle+1}\)  
 总代价 \(d = α·d_{\text{cls}} + β·d_{\text{bce}} + γ·d_{\text{dice}}\)  
 把 \(d\) 填到 \(Q×\#GT\) 矩阵 → 匈牙利算法找最小成本匹配 \({\cal M}\)。

–––– 2.2 四项损失 ––––  
匹配后对每对 \((j,k) ∈ {\cal M}\) 计算：  

(1) **分类 CE**  
\[
  L_{\text{cls}} = \frac1Q \sum_{j=1}^{Q}  
      \text{CE}\!\bigl(c_j,\ y_{\text{tgt}(j)}\bigr)
\]  
未匹配查询以 “背景” 作为标签。

(2) **掩码 BCE**  
\[
  L_{\text{bce}} = \frac1{Q} \sum_{(j,k)∈{\cal M}}
      \frac1N \sum_{i=1}^{N}  
      \bigl[\,g_{ki}\log q_{ji} + (1-g_{ki})\log(1-q_{ji})\bigr] (-)
\]

(3) **掩码 Dice**  
\[
  L_{\text{dice}} = \frac1{Q} \sum_{(j,k)∈{\cal M}}  
      1-\frac{2\langle q_j,g_k\rangle}{\langle q_j,q_j\rangle+\langle g_k,g_k\rangle+1}
\]

(4) **置信度回归**  
  - 先计算 IoU\((q_j,g_k)\) 当作目标分数 \(s_k\)  
  - 预测 `query_score  s_j^p`  
\[
  L_{\text{score}}=\frac1{|{\cal M}|}\sum_{(j,k)}\|s_j^p-s_k\|_2^2
\]

加权求和  
\[
  L_{\text{inst}} = w_0L_{\text{cls}} + w_1L_{\text{bce}} + w_2L_{\text{dice}} + w_3L_{\text{score}}
\]

–––– 2.3（可选）BBox 回归 ––––  
`MixedInstanceCriterion` 在匹配后，把每个查询预测的 6D box \(\hat b_j\) 与 GT 盒 \(b_k\) 做 L1：  
\[
  L_{\text{bbox}} = \frac1{|{\cal M}|} \sum_{(j,k)} \|\hat b_j - b_k\|_1
\]

────────────────────────────  
3. 跨帧 Transformer 损失 L_tdt  
────────────────────────────  
【模块】`CrossFrameCriterion`（见 `tdt_loss.py`）  
【场景】MV-Online，模型用 `TimeDividedTransformer` 预测帧间匹配矩阵。  

(1) **匹配 BCE**  
  - 预测 `P_{t} ∈ ℝ^{Q×Q}`：第 t 帧 query 与第 t+1 帧 query 的匹配概率  
  - GT 矩阵 `G_t`：由两帧预测掩码在点云上的 IoU>0.5 判定  
  \[
    L_{\text{match}} = -\frac1{V-1} \sum_{t=1}^{V-1}  
        \langle G_t,\log P_t\rangle + \langle1-G_t,\log(1-P_t)\rangle
  \]

(2) **特征一致性**  
  - Transformer 也会输出更新后 query feature \(q_t\)。  
  - 相邻帧 L2：\(L_{\text{cons}}=\frac1{V-1}\sum_t\|q_t-q_{t+1}\|_2^2\)

\[
  L_{\text{tdt}} = λ_1 L_{\text{match}} + λ_2 L_{\text{cons}}
\]

────────────────────────────  
4. 在线合并损失 L_merge  
────────────────────────────  
【模块】`ScanNetMergeCriterion_Fast` / `_Seal`  
【背景】`instance_merge.OnlineMerge.merge()` 会把跨帧匹配后的查询掩码合并成**全局实例 id**。  

• 预测：`global_id_pred ∈{0…K}` 每点所属的合并实例  
• GT：`global_id_gt   ∈{0…K}` (由 3D bbox 标签对齐)  

简单交叉熵：  
\[
  L_{\text{merge}} = -\frac1N\sum_i \log p\bigl(global\_id\_gt(i)\bigr)
\]

────────────────────────────  
5. CLIP 对比损失 L_clip  
────────────────────────────  
【模块】`ClipConsCriterion`  
【输入】  
  • `feat_fusion_global ∈ ℝ^{M×d}`：对每个实例/块池化后的融合特征 (d=96)  
  • `clip_global        ∈ ℝ^{M×d}`：图像 CLS token 经过 MLP 投到同维度  
【计算：NT-Xent（对比学习）】  
\[
  \text{sim}(i,j)=\frac{\langle f_i, c_j\rangle}{\|f_i\|\|c_j\|}  
\]
\[
  L_{\text{clip}} = -\frac1M\sum_{i=1}^{M}\log
      \frac{e^{\text{sim}(i,i)/τ}}
           {\sum_{j=1}^{M} e^{\text{sim}(i,j)/τ}}
\]  
τ 是温度（默认 0.07）。

────────────────────────────  
6. 总损失回顾  
────────────────────────────  
```
total = L_sem + L_inst 
      + (MV-Online) [ L_tdt + L_merge ] 
      + (BiFusion)  L_clip 
      + (bbox任务)  L_bbox
```
各 \(w,λ\) 系数在 config 中 `loss_weight`/`matcher.costs` 指定，可随需求调节。

────────────────────────────  
名词/概念小贴士  
────────────────────────────  
• **Super-point（超像素）**：用 SAM 把 2D 像素切块后沿深度映射到点云形成的小簇，网络直接在簇级别预测掩码，显著减小显存。  
• **Query**：OneFormer3D 里类似 DETR 的 learnable mask token，充当 “候选实例”。  
• **Hungarian matcher**：解决「查询数量固定、GT 数变化」的对齐问题；本质是最小化总代价的二分图匹配算法。  
• **Dice loss**：衡量两个二值掩码的重叠程度，数值越小越相似。  
• **IoU**：Intersection / Union，用于评估掩码或 bbox 的重合度。  
• **NT-Xent**：Normalized Temperature-scaled Cross-Entropy，对比学习常用，鼓励正对齐、负分离。  

这样，每条损失如何取得输入、怎么计算、在整体损失中的角色就全部展开了。希望这份「逐式详解」能帮助你真正看懂 ESAM 的训练流程！