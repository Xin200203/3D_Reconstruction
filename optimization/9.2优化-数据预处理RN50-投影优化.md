# 最终版修改指南（RN50-layer2 预计算 + 稳定投影）

下面给你一份**可直接照着改**的版本，覆盖两块：
① 数据预处理时用 **CLIP-RN50 的 layer2 输出**；
② 点→像素投影与整条 pipeline 的关键细节（不再“猜”外参方向，统一为**确定性**处理）。

---

## 1）数据预处理：用 RN50 layer2 离线出 2D 特征

### 1.1 输入、归一化与输出形状

* **原图尺寸**：RGB 为 `H×W = 480×640`，与深度同分辨率。
* **特征尺度**：RN50 的总 stride 到 layer2 为 **8**（conv1 s=2 + pool s=2 + layer2 再下采样一次），
  所以 **layer2** 输出的特征图尺寸：`Hf×Wf = 60×80`，**通道数 C=512**。
* **保存格式**：建议将每帧特征存成 `float16` 的 `.pt/.npy`，键名统一为 **`clip_pix`**（与现有管线一致，pack 阶段会打到样本里），配置里确有 `clip_pix` 这个键被打包传入模型。

### 1.2 预处理同时保存的元信息（**务必一致**）

* **内参**：`fx, fy, cx, cy`（float32）。
* **外参（居中后的 C2W）**：文件里叫 `pose_centered`，它是**相机到世界的变换（C2W）**，**只把平移减去了 `xyz_offset`**（旋转不变）。这一点在你当前的数据脚本里是明确的：

  * `pose_centered[:3, 3] = pose[:3, 3] - xyz_offset`；
  * 同时点云也保存了两套：**unaligned**（原世界系）与 **zero-centered**（减了 `xyz_offset`）。
* **坐标系选择（训练用）**：我们**只用 `zero-centered` 的 unaligned\_xyz** 作为「世界系（记作 World0）」来训练与投影，避免和 axis-aligned 混用（你的脚本里两套都在存，我们只吃前者）。
* **图像尺寸**：`H=480, W=640`（后面算缩放要用），以及是否畸变（若无则置空）。

> 小结：**预处理输出** = `clip_pix (512×60×80, fp16)` + `intrinsics` + `pose_centered (C2W, t减offset)` + `xyz_offset` + `image_size (480×640)` + 点云（**zero-centered**）。

---

## 2）投影与整条 Pipeline（确定性版本）

### 2.1 坐标与变换约定（确定不再“猜”）

* **世界坐标（World0）**：预处理时对所有 3D 点坐标做了 `x_w0 = x_w - xyz_offset` 的**零中心化**。
* **相机位姿**：加载 `pose_centered` 时**按 C2W 使用**（旋转 `R`，平移 `t_c = t - xyz_offset`），然后**显式取逆**得到 `W2C_centered = T_c2w_centered^{-1}`，而不是在前向里“自动判断/猜测”。

  * 我们将**关掉自动推断**（`auto_pose`、`_pick_w2c`）这一路，确保**每帧一律执行 `W2C = inverse(C2W_centered)`**。

> 结论（固定做法）：
> **输入的 `pose_centered` 一定是 C2W（t 已减 offset）→ 前向里统一取逆为 W2C 用。**

### 2.2 3D→2D 像素与特征格坐标

给定点 `P_w0 = (x,y,z)`（World0），和
`T_w2c = [R^T | -R^T t_c] = (T_c2w_centered)^{-1}`：

1. **到相机坐标**：`P_c = (x_c, y_c, z_c) = R^T (P_w0 - t_c)`（或一次性右乘齐次 W2C）。
2. **针孔投影**：
   `u = fx * (x_c / z_c) + cx`，`v = fy * (y_c / z_c) + cy`，要求 `z_c > 0` 且在图像边界内。
3. **像素→特征图索引**（因为我们用的是 60×80 的 layer2 特征）：
   `u_f = u * (Wf / W)`，`v_f = v * (Hf / H)`，其中 `Wf=80, Hf=60, W=640, H=480`。
4. **grid\_sample 归一化坐标**（`align_corners=False`）：
   `x_norm = 2*(u_f + 0.5)/Wf - 1`，`y_norm = 2*(v_f + 0.5)/Hf - 1`。
   你的编码器里已有同样的像素→网格归一化实现（`_pixels_to_grid` 路径），采用 `align_corners=False` 的归一化。
5. **采样与掩码**：
   在 `project_and_sample_with_geometry` 里会完成投影、可见性与越界掩码处理，再 `grid_sample` 拿到 2D 特征。

> 注：我们坚持**分辨率一致的几何缩放**，不做额外 crop/resize 偏移；这保持了点/像素对齐的**一一性**（正是你项目里「2D-3D 局部投影 + 几何融合」需要的）。

### 2.3 2D 分支如何“吃”预计算特征

* **从样本中拿特征**：`cam_meta['clip_pix']`（形状 `512×60×80`）直接作为 2D 特征图输入 encoder；配置 Pipeline 已在 test/train 打包 `clip_pix`。
* **feat\_space 与头部适配**：模型侧将 `feat_space` 设为我们自定义的 **`clip_custom_60x80`**，并把 **precomp adapter** 设为 `Linear(512→256)` + 正则化，以便和 3D 通道（256）对齐。
* **投影融合**：进入 `project_and_sample_with_geometry`，再经 **LiteFusionGate** 做门控融合（`α·f2d + (1-α)·f3d` 的轻量门控机理，见你的 encoder 实现注释）。

### 2.4 关键张量的**统一形状**

* 预计算 2D：`F2D_raw ∈ ℝ^{512×60×80}` → `Adapter(512→256)` → `F2D ∈ ℝ^{256×60×80}`
* 3D 干支路：Minkowski U-Net 输出 `C3D=96`，经 3D→融合通道投影 `96→256` 得 `F3D ∈ ℝ^{N_pts×256}`
* 投影采样后：`F2D(P)` 与 `F3D(P)` 在**每个点**拼或门控融合 → 下游 head（实例分割/匹配等）

---

## 3）**必须修改/确认**的代码点（Checklist）

1. **数据侧（预处理脚本）**

* 用 **RN50** 提取 **layer2**，输出 `512×60×80`，存 `clip_pix`（fp16）。
* 元信息里**明确**存：`intrinsics`、`pose_centered(C2W, t−xyz_offset)`、`xyz_offset`、`H,W`、以及**zero-centered** 点坐标。
  这些字段与你当前脚本保持一致：保存了 zero-centered 点与 `pose_centered`（t 减 offset）。

2. **数据管线（Dataset/Pipeline）**

* 确保 `LoadClipFeature` 正确把 `clip_pix` 加载并随 `Pack3DDetInputs_` 传给模型。

3. **编码器（BiFusionEncoder）**

* **禁用自动外参推测**：把 `auto_pose` 相关逻辑置 `False`，不再调用 `_pick_w2c`；
  始终执行 `W2C = inverse(pose_centered_C2W)`（源码里 `_pick_w2c`/`auto_pose` 分支是存在的）。
* **feat\_space** 设为 `clip_custom_60x80` / `precomp_60x80` 一致；**adapter**：`512→256`。
* **像素到网格**：确保走 `_pixels_to_grid`（`align_corners=False` 的归一化公式），避免坐标系漂移。
* **几何采样**：沿用 `project_and_sample_with_geometry` 做可见性与边界掩码。

---

## 4）最小验收用例（强烈建议跑一下）

* **几何一致性**：随机采样 10k 个点，统计 `z_c>0` 且落入 `0≤u<W, 0≤v<H` 的比例，若 <60% 请检查外参/单位。
* **再投影漂移**：把点投到像素再回采 2D 特征，邻域均值上色回点云，肉眼检查是否与 RGB 纹理对应。
* **通道/分辨率**：断言 `clip_pix.shape == (512,60,80)`，并在 encoder 中 adapter 后变为 `(256,60,80)`。

---

## 5）为什么用 RN50-layer2（而不是更深层）

* layer2 仍保持**较密集的空间响应**（stride=8），对**细小结构**与**遮挡边界**更友好；越往后层，感受野与语义更强，但**空间覆盖**与**几何对齐的精确性**会自然下降（这也符合你项目“局部投影+几何融合”的需求）。
* 你现有的融合、采样与 `grid_sample` 公用件就是为这种**稠密对齐**写的（`_pixels_to_grid` 与几何采样函数已就位）。

---

## 6）落地参数与形状一览（方便你对表）

* **RN50 layer2**：`C=512, Hf×Wf=60×80` → adapter `512→256`。
* **像素→特征图缩放**：`scale_x=80/640=0.125`，`scale_y=60/480=0.125`（无需额外偏移）。
* **归一化到 grid**（`align_corners=False`）：
  `x_norm = 2*(u_f+0.5)/80 − 1`，`y_norm = 2*(v_f+0.5)/60 − 1`。
* **外参**：读入 **C2W（t 已减 offset）** → **固定取逆**为 **W2C** 使用；不再自动判断。
* **数据键位**：`clip_pix`、`cam_info`、`imgs` 在 pack 中已传入。

---

### 一句话总结

* **预处理**：离线提 RN50-layer2 → `clip_pix(512×60×80)` + `pose_centered(C2W,t−offset)` + `xyz_offset` + `intrinsics` + **zero-centered** 点；
* **前向**：**固定** `W2C = inverse(pose_centered)`，针孔投影 → `scale` 到 60×80 → `_pixels_to_grid`（`align_corners=False`）→ `grid_sample` 取 2D 特征；
* **融合**：`512→256` 适配后与 3D（→256）按 LiteFusionGate 融合，走你现有 head 即可。

