#!/usr/bin/env python3
"""
ä¿®å¤QueryDecoderæƒé‡åçš„æµ‹è¯•è„šæœ¬
"""

import torch
import torch.nn as nn
import sys
import os
sys.path.insert(0, '/home/nebula/xxy/ESAM')

from mmengine.config import Config
from mmengine.runner import Runner

def patch_query_decoder():
    """ç»™QueryDecoderæ‰“è¡¥ä¸ï¼Œæ­£ç¡®åŠ è½½input_projæƒé‡"""
    
    # åŠ è½½ä¿®å¤é…ç½®
    if os.path.exists('/home/nebula/xxy/ESAM/decoder_fix_config.pth'):
        fix_config = torch.load('/home/nebula/xxy/ESAM/decoder_fix_config.pth', map_location='cpu')
        print(f"ğŸ”§ åŠ è½½ä¿®å¤é…ç½®: {fix_config['expected_in_channels']} -> {fix_config['d_model']}")
        
        # è·å–åŸå§‹QueryDecoderç±»
        from oneformer3d.query_decoder import QueryDecoder
        original_forward_iter_pred = QueryDecoder.forward_iter_pred
        
        def patched_forward_iter_pred(self, sp_feats, p_feats, queries, super_points, prev_queries=None):
            """ä¿®å¤åçš„forwardæ–¹æ³•"""
            
            # å¦‚æœinput_projæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–
            if self.input_proj is None and sp_feats and "SP" in self.cross_attn_mode:
                print(f"ğŸ”§ ä½¿ç”¨é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–input_proj")
                
                # åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç»“æ„
                self.input_proj = nn.Sequential(
                    nn.Linear(fix_config['expected_in_channels'], fix_config['d_model']),
                    nn.LayerNorm(fix_config['d_model']),
                    nn.ReLU()
                ).to(sp_feats[0].device)
                
                # åŠ è½½é¢„è®­ç»ƒæƒé‡
                with torch.no_grad():
                    self.input_proj[0].weight.copy_(fix_config['linear_weight'])
                    self.input_proj[0].bias.copy_(fix_config['linear_bias'])
                    if fix_config['norm_weight'] is not None:
                        self.input_proj[1].weight.copy_(fix_config['norm_weight'])
                        self.input_proj[1].bias.copy_(fix_config['norm_bias'])
                
                print(f"âœ… input_projæƒé‡åŠ è½½å®Œæˆ")
            
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            return original_forward_iter_pred(self, sp_feats, p_feats, queries, super_points, prev_queries)
        
        # åº”ç”¨è¡¥ä¸
        QueryDecoder.forward_iter_pred = patched_forward_iter_pred
        print("ğŸ”§ QueryDecoderè¡¥ä¸å·²åº”ç”¨")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ä¿®å¤é…ç½®ï¼Œè·³è¿‡æƒé‡ä¿®å¤")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    print("ğŸš€ å¼€å§‹ä¿®å¤åçš„æµ‹è¯•")
    
    # åº”ç”¨è¡¥ä¸
    patch_query_decoder()
    
    # è®¾ç½®ç¯å¢ƒ
    os.environ['PYTHONPATH'] = '/home/nebula/xxy/ESAM:' + os.environ.get('PYTHONPATH', '')
    
    # åŠ è½½é…ç½®
    config_path = 'configs/ESAM_CA/sv_bifusion_scannet200.py'
    checkpoint_path = '/home/nebula/xxy/ESAM/work_dirs/enhanced_bifusion_debug/epoch_49.pth'
    work_dir = 'work_dirs/test_epoch49_ca_fixed'
    
    print(f"ğŸ“‚ é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ğŸ¯ æ¨¡å‹æ–‡ä»¶: {checkpoint_path}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {work_dir}")
    
    # åŠ è½½é…ç½®
    cfg = Config.fromfile(config_path)
    
    # è®¾ç½®CAæ¨¡å¼
    cfg.test_evaluator.eval_mode = 'cat_agnostic'
    cfg.work_dir = work_dir
    cfg.load_from = checkpoint_path
    
    # åˆ›å»ºrunnerå¹¶æµ‹è¯•
    runner = Runner.from_cfg(cfg)
    runner.test()
    
    print("âœ… ä¿®å¤åçš„æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()
