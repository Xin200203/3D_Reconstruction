## 跨帧 Transformer （Inter-frame Slot-Transformer）——设计全解

> 目标 = **动态刷新实例特征** + **输出注意力矩阵指导匹配 / 融合**
> 约束 = **全局坐标系**、**无实例回收**、**特征已具备几何-语义双表征**

---

### 1 输入与符号

| 变量                                        | 维度            | 含义                                                       |
| ----------------------------------------- | ------------- | -------------------------------------------------------- |
| $ \mathbf{Q}\!=\![q_i]_{i=1}^{N_c}$       | $N_c\times D$ | 当前帧 *candidate* instance token（来自单帧 Decoder）             |
| $ \mathbf{K}\!=\![k_j]_{j=1}^{N_m}$       | $N_m\times D$ | Memory 中 *slot* token（每个已追踪实例 1 票）                       |
| $ \mathbf{P}^c\in\mathbb R^{N_c\times 9}$ | —             | 当前实例几何嵌入：质心 xyz$_w$+ sin-cos($xyz$) + bbox size + height |
| $ \mathbf{P}^m\in\mathbb R^{N_m\times 9}$ | —             | Memory 几何嵌入（同上，延用最新帧观测）                                  |
| $ \mathbf{M}\in\{0,1\}^{N_m}$             | —             | slot **mask**（=1 表示占用；本项目不回收故恒 1）                        |

> **可选**：帧间 ΔPose $ \Delta\mathbf{T}_{w\leftarrow cam}$ 作为 **帧 token** 额外输入，仅在帧级全局注意里使用。

---

### 2 总体流程

```
Current frame instance set  ─┐
                             │ step0 预筛选 (voxel hash / KD-tree)
Memory slot set          ───▶│       取 K≈32 近邻，减少 Quadratic
                             ▼
  ┌───────────────┐
  │ Slot-Transformer│  ←  L 层堆叠 (默认 L=3)
  └───────────────┘
        │         │
        │attn map │updated slot feature
        ▼         ▼
   匹配矩阵 A   Memory refresh
        │
        ▼
   关联 & 融合 (≥τ) ;  新实例初始化 (<τ)
```

---

### 3 核心层：**Geometry-biased Cross Attention (G-XCA)**

#### 3.1 公式

对第 $l$ 层，第 $h$ 头：

$$
\begin{aligned}
\mathbf Q_h &= \mathbf W_Q^{(l,h)} (\mathbf Q + \mathbf P^c) \\
\mathbf K_h &= \mathbf W_K^{(l,h)} (\mathbf K + \mathbf P^m) \\
\mathbf V_h &= \mathbf W_V^{(l,h)} (\mathbf K) \\
\Delta_{ij} &= \textsf{MLP}\big([\mathbf P^c_i \, \| \, \mathbf P^m_j ]\big)\in\mathbb R  \\
\alpha_{ij}^{(h)} &=\textsf{softmax}_j\!\left(
  \frac{\mathbf Q_{h,i}\cdot\mathbf K_{h,j}}{\sqrt{d_h}} + \beta\!\cdot\!\Delta_{ij}
\right)
\end{aligned}
$$

* **几何偏置 $\Delta_{ij}$**：可学习两层 MLP；输入拼接 (Δxyz, IoU of bbox, height diff)。
* **$\beta$** 全局标量（可学习）控制几何 vs 语义权重。

#### 3.2 更新

$$
\tilde q_i=\sum_{j}\alpha_{ij}\mathbf V_{j}
,\qquad
q_i^{\text{new}}=\textsf{GRU}(q_i,\tilde q_i)
$$

> **只更新 Query（当前帧）** —— Memory 先不变，防止累积漂移；
> 最后一层后再执行 **Slot Refresh**（见 §4）。

#### 3.3 Self-Attention 补充

* 在每层 G-XCA 之后，对 $\mathbf Q$ 做一次 **点内 SA**（与 Mask3D 相同）增强帧内一致性；
* Memory 不做 SA，保持稀疏稳定。

---

### 4 Slot Refresh & 匹配矩阵

1. **相似度矩阵** $\mathbf A\in\mathbb R^{N_c\times N_m}$
   直接取最后一层加权和：$A_{ij}=\alpha^{(L)}_{ij}$。
2. **匈牙利匹配** (train) / **阈值 τ** (inference) 得到一一映射表 $\pi$。
3. **融合更新**

   * 若匹配：

     $$
       k_j \leftarrow \textsf{EMA}(k_j, \; q_i^{\text{new}});\quad
       \text{count}_j+=1
     $$
   * 若未匹配： 新建 slot，拷贝 $q_i^{\text{new}}$。
   * 几何元数据（质心 / bbox）用同帧新观测 **Kalman-Fusion**。

---

### 5 训练信号

| Loss                            | 监督             | 说明                                            |
| ------------------------------- | -------------- | --------------------------------------------- |
| **$\mathcal L_{\text{match}}$** | GT instance id | Cross-entropy on $\mathbf A$（Hungarian label） |
| **$\mathcal L_{\text{cons}}$**  | 自监督            | 同一 slot 连续帧特征一致性（InfoNCE）                     |
| **$\mathcal L_{\text{det}}$**   | 有 GT 时         | Mask3D 类别 / mask loss                         |

---

### 6 为何简洁但有效？

* 与之前“双头方案”相比：

  * **删除 Memory→Query 反向 CA**（只保留 Q→K），靠 GRU+EMA 即可把新信息写回；
  * **不更新点云**，只更新 slot feature ⇒ 避免累积畸变，跑满数千帧依然稳定。
* 几何偏置提供了**先验对齐**，弥补单向注意力信息量不足；sin-cos 高频 + bbox size 足可区分相邻物体。
* EMA 写回在实验中比完整的 Key/Value 重新生成更抗噪声（参考 *GFocal3D* 的观察）。

---

### 7 实现细节

```python
class GXCA(nn.Module):
    def __init__(self, d, nhead):
        ...
        self.mlp_bias = nn.Sequential(
            nn.Linear(9*2, d), nn.ReLU(), nn.Linear(d, 1))
        self.beta = nn.Parameter(torch.zeros(1))

    def forward(self, q, k, pc, pm, mask_mem):
        # q: [B Nc D]   k: [B Nm D]
        bias = self.mlp_bias(torch.cat([pc.unsqueeze(2).expand(-1,-1,Nm,-1),
                                        pm.unsqueeze(1).expand(-1,Nc,-1,-1)],-1)).squeeze(-1)
        attn = (q@k.transpose(-2,-1))/sqrt(d) + self.beta*bias
        attn = attn.masked_fill(mask_mem==0, -1e4)
        attn = attn.softmax(-1)
        v    = k
        out  = attn@v
        q_up = self.gru(out, q)
        return q_up, attn
```

---

### 8 与旧回答方案的差异与取舍

| 方案                            | 计算 | 精度   | 复杂度 | 备注                  |
| ----------------------------- | -- | ---- | --- | ------------------- |
| **双向 Cross-Attn + Time-Head** | 高  | ★★★★ | 较高  | 可微对位 + 历史显式聚焦       |
| **当前简洁版 G-XCA**               | 中  | ★★★☆ | 低   | 简化写操作，用几何 bias 填补信息 |

> **推荐**：先实现 **G-XCA 简洁版** 快速验证；若后期发现匹配召回仍不足，再叠加 Memory-to-Query 反向头 + slot-id Key。

---

结论：该跨帧 Transformer 以**几何偏置单向 Cross-Attention + GRU 写回**为核心，在保持网络轻量的同时，借助高频 xyz 编码获得稳定匹配；输出注意力矩阵直接驱动实例融合，满足线上增量 3D 场景重建的实时需求。
