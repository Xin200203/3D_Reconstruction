# ESAM è¿›é˜¶è®­ç»ƒæŒ‡å— â€“ Bi-Fusion Encoder & Time-Divided Transformer

> æœ¬æ–‡æ¡£é¢å‘å¸Œæœ›åœ¨ **EmbodiedSAM / ESAM** æ¡†æ¶ä¸­å¯ç”¨ _2D-3D Bi-Fusion ç‰¹å¾ç¼–ç å™¨_ åŠ _è·¨å¸§ Time-Divided Transformer_ çš„ä½¿ç”¨è€…ï¼Œè®°å½•æ‰€éœ€çš„æœ€å°ä¿®æ”¹ä¸å¯é€‰æ‹“å±•ï¼Œä¿æŒä¸åŸç‰ˆé…ç½®å®Œå…¨å…¼å®¹ï¼ˆå³ **å¯æŒ‰éœ€å¼€å…³**ï¼‰ã€‚

---

## 1. ç¯å¢ƒå‰æ
1. å·²æŒ‰ `docs/installation.md` é…ç½® Pythonâ‰¥3.8ã€PyTorchã€MinkowskiEngineã€MMDetection3D ç­‰ä¾èµ–ã€‚
2. è¿½åŠ ä¾èµ–ï¼ˆrequirements.txt å·²åˆ—å‡ºï¼Œä»…æé†’ï¼‰ï¼š
   ```bash
   pip install open_clip_torch==2.22
   ```
3. æ•°æ®é›†ç›®å½•ä¸ `.pkl` ç´¢å¼•å·²æŒ‰ `docs/dataset_preparation.md` å‡†å¤‡å®Œæ¯•ã€‚

---

## 2. é…ç½®æ–‡ä»¶å±‚çº§å›é¡¾
ESAM é‡‡ç”¨ **mmdet3d** çš„ Config ä½“ç³»ï¼šä»¥ `configs/<variant>/<file>.py` ä¸ºå…¥å£ï¼Œæ•´ä½“ç»“æ„å¦‚ä¸‹
```python
model = dict(
    voxel_size=0.02,
    backbone=...,           # 3D Sparse UNet
    pool=...,
    decoder=...,            # Query Decoder
    criterion=...,          # æŸå¤±
    # æ–°å¢ä¸¤å¤„å¯é€‰æ¨¡å— â†“â†“â†“
    bi_encoder=None,        # ğŸ‘‰ 2D-3D ç‰¹å¾èåˆ (Bi-Fusion)
    clip_criterion=None,    # ğŸ‘‰ èåˆä¸€è‡´æ€§æ­£åˆ™ (å¯é€‰)
)

train_pipeline = [...]

test_cfg = dict(
    merge_type='concat',    # Online / Offline åŒºåˆ†
    inscat_topk_insts=100,
    # æ–°å¢ğŸ‘‡ è·¨å¸§ Transformer çš„æ„é€ å‚æ•°
    tformer_cfg=None,
)
```
è‹¥ **bi_encoder / tformer_cfg** è®¾ä¸º `None` å³é€€åŒ–ä¸ºåŸå§‹ ESAMã€‚

---

## 3. å¯ç”¨ Bi-Fusion Encoder
### 3.1 ä¿®æ”¹ `model` å­—å…¸
```python
bi_encoder = dict(
    type='BiFusionEncoder',         # å·²åœ¨ oneformer3d/__init__.py æ³¨å†Œ
    clip_pretrained='openai',       # ViT-B/16 æƒé‡æ¥æºï¼Œå¯æ¢
    voxel_size=0.02,               # ä¸å…¨å±€ä¸€è‡´å³å¯
    freeze_blocks=2,               # ä»…å¾®è°ƒå 2 ä¸ª Transformer block
)

# å¯é€‰ï¼šCLIP ä¸€è‡´æ€§æ­£åˆ™
clip_criterion = dict(
    type='ClipConsCriterion',      # oneformer3d/bife_clip_loss.py
    loss_weight=0.05,              # Î»_clip
)
```
âš ï¸ åŒæ—¶ç§»é™¤ `img_backbone`ï¼ˆBi-Fusion å†…éƒ¨å·²å¸¦ CLIP-ViTï¼‰ï¼Œå¦åˆ™ä¼šå†²çªã€‚

### 3.2 ä¿®æ”¹æ•°æ®ç®¡çº¿
Bi-Fusion éœ€è¦ RGB åŠç›¸æœºå†…ã€å¤–å‚ï¼š
```python
train_pipeline[  # and test_pipeline
    ...,
    dict(type='LoadAdjacentDataFromFile',
         with_img=True,
         with_cam=True,
         # å…¶ä½™å‚æ•°ä¿æŒä¸å˜
    ),
    ...
]
```
ç®¡çº¿ä¼šåœ¨ `batch_inputs_dict` ä¸­å¡«å……ï¼š
```
points  : List[(N_i,6)]
imgs    : List[Tensor 3Ã—HÃ—W]
cam_info: List[dict {intrinsics, extrinsics}]
```
`mixformer3d.py` å·²æ ¹æ® `bi_encoder is not None` è‡ªåŠ¨åˆ‡æ¢åˆ°èåˆåˆ†æ”¯ï¼Œæ— éœ€æ›´å¤šæ”¹åŠ¨ã€‚

---

## 4. å¯ç”¨ Time-Divided Transformerï¼ˆè·¨å¸§åŒ¹é…ï¼‰
ä»…é€‚ç”¨äº **MV / Online** æ¨ç†é…ç½®ï¼›è®­ç»ƒé˜¶æ®µå¯é€‰æ˜¯å¦è”åˆç›‘ç£ã€‚

### 4.1 `test_cfg` ä¸­å¼€å¯
```python
test_cfg = dict(
    merge_type='learnable_online',   # ç¡®ä¿è°ƒç”¨ OnlineMerge
    inscat_topk_insts=100,
    tformer_cfg=dict(
        type='TimeDividedTransformer',
        d_model=256,
        nhead=8,
        num_layers=3,
        dropout=0.0,
    ),
)
```
`OnlineMerge` æ£€æµ‹åˆ° `tformer_cfg` åä¼šå®ä¾‹åŒ– Transformer æ›¿ä»£åŸæœ‰æ··åˆåˆ†æ•°çŸ©é˜µã€‚

### 4.2 è®­ç»ƒç›‘ç£ï¼ˆå¯é€‰ï¼‰
è‹¥å¸Œæœ›å¯¹è·¨å¸§æ³¨æ„åŠ›çŸ©é˜µåŠ å…¥ç›‘ç£ï¼ˆ`CrossFrameCriterion`ï¼‰:
1. ç¡®è®¤ `oneformer3d/instance_criterion.py` ä¸­å·²é›†æˆè¯¥ lossï¼›
2. åœ¨ `model.criterion` å¯¹åº” loss æƒé‡é‡ŒåŠ å…¥ `L_match`, `L_cons`ã€‚

---

## 5. ç¤ºä¾‹é…ç½®é›†
| ä»»åŠ¡ | cfg æ–‡ä»¶ | å…³é”®æ”¹åŠ¨ |
| ---- | -------- | -------- |
| ScanNet200-SV (Bi-Fusion) | `configs/ESAM/ESAM_sv_scannet200_bifusion.py` | Section 3.1 & 3.2 |
| ScanNet200-MV (Bi-Fusion + T-former Online) | `configs/ESAM_CA/ESAM_online_scannet200_CA_bifusion_tf.py` | Section 3 + 4 |

å¤åˆ¶åŸ cfg å¹¶æŒ‰ç« èŠ‚æ›¿æ¢å­—æ®µå³å¯ã€‚

---

## 6. è®­ç»ƒ / æ¨ç†æŒ‡ä»¤æ¨¡æ¿
```bash
# å• GPU è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 \
python tools/train.py \
    <cfg_path>.py \
    --work-dir work_dirs/$(basename <cfg_path>)

# æ¨ç† / è¯„æµ‹
CUDA_VISIBLE_DEVICES=0 \
python tools/test.py \
    <cfg_path>.py \
    work_dirs/$(basename <cfg_path>)/epoch_*.pth \
    --work-dir work_dirs/$(basename <cfg_path>)
```
> è‹¥ä½¿ç”¨å¤š GPUï¼Œå¯åŠ  `--launcher pytorch` æˆ–æ”¹ç”¨ slurm åˆ†å¸ƒå¼è„šæœ¬ï¼Œå‡ä¸ MMEngine ä¿æŒä¸€è‡´ã€‚

---

## 7. æ•…éšœæ’æŸ¥ Checklist
1. **å†…å­˜ä¸è¶³**ï¼šé™ä½æ‰¹é‡ã€å¢å¤§ `freeze_blocks`ã€æˆ–å¯ç”¨æ··åˆç²¾åº¦ (`--amp`)ã€‚
2. **æ‰¾ä¸åˆ° `imgs` é”®**ï¼šæ£€æŸ¥ `with_img=True`ã€‚ç¡®ä¿æ•°æ®é›†ç›®å½•ä¸‹æœ‰ RGB png å¹¶åœ¨ meta ä¸­è®°å½•è·¯å¾„ã€‚
3. **tformer æ— æ•ˆæœ**ï¼šç¡®è®¤ `merge_type='learnable_online'` ä¸”æ•°æ®åŠ è½½ä¸º **MV**ï¼ˆåŒä¸€åºåˆ—å¤šå¸§ï¼‰ã€‚
4. **CLIP æƒé‡ä¸‹è½½å¤±è´¥**ï¼šæå‰æ‰‹åŠ¨æ”¾åˆ° `~/.cache/clip` æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ `OPENAI_CLIP_CACHE_PATH`ã€‚

---

> æ›´æ–°äº 2025-06-24
