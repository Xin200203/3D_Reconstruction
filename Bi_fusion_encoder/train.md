# ESAM è¿›é˜¶è®­ç»ƒæŒ‡å— â€“ Bi-Fusion Encoder & Time-Divided Transformer

> æœ¬æ–‡æ¡£é¢å‘å¸Œæœ›åœ¨ **EmbodiedSAM / ESAM** æ¡†æ¶ä¸­å¯ç”¨ _2D-3D Bi-Fusion ç‰¹å¾ç¼–ç å™¨_ åŠ _è·¨å¸§ Time-Divided Transformer_ çš„ä½¿ç”¨è€…ï¼Œè®°å½•æ‰€éœ€çš„æœ€å°ä¿®æ”¹ä¸å¯é€‰æ‹“å±•ï¼Œä¿æŒä¸åŸç‰ˆé…ç½®å®Œå…¨å…¼å®¹ï¼ˆå³ **å¯æŒ‰éœ€å¼€å…³**ï¼‰ã€‚

---

## 1. ç¯å¢ƒå‰æ
1. å·²æŒ‰ `docs/installation.md` é…ç½® Pythonâ‰¥3.8ã€PyTorchã€MinkowskiEngineã€MMDetection3D ç­‰ä¾èµ–ã€‚
2. è¿½åŠ ä¾èµ–ï¼ˆrequirements.txt å·²åˆ—å‡ºï¼Œä»…æé†’ï¼‰ï¼š
   ```bash
   pip install open_clip_torch==2.22
   ```
3. æ•°æ®é›†ç›®å½•ä¸ `.pkl` ç´¢å¼•å·²æŒ‰ `docs/dataset_preparation.md` å‡†å¤‡å®Œæ¯•ã€‚

---

## 2. é…ç½®æ–‡ä»¶å±‚çº§å›é¡¾
ESAM é‡‡ç”¨ **mmdet3d** çš„ Config ä½“ç³»ï¼šä»¥ `configs/<variant>/<file>.py` ä¸ºå…¥å£ï¼Œæ•´ä½“ç»“æ„å¦‚ä¸‹
```python
model = dict(
    voxel_size=0.02,
    backbone=...,           # 3D Sparse UNet
    pool=...,
    decoder=...,            # Query Decoder
    criterion=...,          # æŸå¤±
    # æ–°å¢ä¸¤å¤„å¯é€‰æ¨¡å— â†“â†“â†“
    bi_encoder=None,        # ğŸ‘‰ 2D-3D ç‰¹å¾èåˆ (Bi-Fusion)
    clip_criterion=None,    # ğŸ‘‰ èåˆä¸€è‡´æ€§æ­£åˆ™ (å¯é€‰)
)

train_pipeline = [...]

test_cfg = dict(
    merge_type='concat',    # Online / Offline åŒºåˆ†
    inscat_topk_insts=100,
    # æ–°å¢ğŸ‘‡ è·¨å¸§ Transformer çš„æ„é€ å‚æ•°
    tformer_cfg=None,
)
```
è‹¥ **bi_encoder / tformer_cfg** è®¾ä¸º `None` å³é€€åŒ–ä¸ºåŸå§‹ ESAMã€‚

## 2.3 ä»£ç ç‰ˆæœ¬ä¾èµ–æ£€æŸ¥
åœ¨çœŸæ­£è®­ç»ƒå‰ï¼Œè¯·ç¡®è®¤ä»¥ä¸‹æ–‡ä»¶å·² **merge åˆ°å½“å‰åˆ†æ”¯**ï¼š
1. `oneformer3d/bi_fusion_encoder.py`ï¼ˆâ‰¥ Step-3ï¼Œæ”¯æŒ batch & extrinsicsï¼‰
2. `oneformer3d/bife_clip_loss.py`
3. `oneformer3d/time_divided_transformer.py` & `instance_merge.py` ä¸­ `tformer_cfg` åˆ†æ”¯
4. `oneformer3d/__init__.py` å·² `import BiFusionEncoder, ClipConsCriterion, TimeDividedTransformer`

è‹¥ä»»ä¸€ç¼ºå¤±ï¼Œåº”å…ˆåœ¨ Bi_fusion_encoder åˆ†æ”¯ rebase/merge åå†è¿›å…¥è®­ç»ƒã€‚

---

## 3. å¯ç”¨ Bi-Fusion Encoder
### 3.1 ä¿®æ”¹ `model` å­—å…¸
```python
bi_encoder = dict(
    type='BiFusionEncoder',         # å·²åœ¨ oneformer3d/__init__.py æ³¨å†Œ
    clip_pretrained='openai',       # ViT-B/16 æƒé‡æ¥æºï¼Œå¯æ¢
    voxel_size=0.02,               # ä¸å…¨å±€ä¸€è‡´å³å¯
    freeze_blocks=2,               # ä»…å¾®è°ƒå 2 ä¸ª Transformer block
)

# å¯é€‰ï¼šCLIP ä¸€è‡´æ€§æ­£åˆ™
clip_criterion = dict(
    type='ClipConsCriterion',      # oneformer3d/bife_clip_loss.py
    loss_weight=0.05,              # Î»_clip
)
```
â¶ **åˆ æ‰** åŸæœ‰ `img_backbone` å­—æ®µï¼›è‹¥åç»­å®éªŒä»éœ€ 2D çº¯å›¾åƒç‰¹å¾ï¼Œå¯å°†å…¶è¿ç§»åˆ° `bi_encoder` å†…éƒ¨æˆ–å¦åŠ  `aux_img_backbone`ã€‚

â· è‹¥æƒ³å†»ç»“ CLIP å®Œå…¨ä¸è®­ç»ƒï¼Œå¯æŠŠ `freeze_blocks=-1`ï¼›è‹¥åªå¾®è°ƒ ViT æœ€åä¸€å±‚ï¼Œä¿æŒ `freeze_blocks=1`ã€‚

â¸ `clip_criterion` åªéœ€è¦åœ¨ *é˜¶æ®µ-I* é¢„è®­ç»ƒé˜¶æ®µç”¨ï¼Œè‹¥ç›´æ¥ç«¯åˆ°ç«¯è®­ç»ƒå¯å°† `loss_weight` è°ƒä½è‡³ `0.01` æˆ–å¹²è„†ç½®ç©ºã€‚

### 3.2 ä¿®æ”¹æ•°æ®ç®¡çº¿
Bi-Fusion éœ€è¦ RGB åŠç›¸æœºå†…ã€å¤–å‚ï¼š
```python
train_pipeline[  # and test_pipeline
    ...,
    dict(type='LoadAdjacentDataFromFile',
         with_img=True,
         with_cam=True,
         # å…¶ä½™å‚æ•°ä¿æŒä¸å˜
    ),
    ...
]
```
ç®¡çº¿ä¼šåœ¨ `batch_inputs_dict` ä¸­å¡«å……ï¼š
```
points  : List[(N_i,6)]
imgs    : List[Tensor 3Ã—HÃ—W]
cam_info: List[dict {intrinsics, extrinsics}]
```
`mixformer3d.py` å·²æ ¹æ® `bi_encoder is not None` è‡ªåŠ¨åˆ‡æ¢åˆ°èåˆåˆ†æ”¯ï¼Œæ— éœ€æ›´å¤šæ”¹åŠ¨ã€‚

---

## 4. å¯ç”¨ Time-Divided Transformerï¼ˆè·¨å¸§åŒ¹é…ï¼‰
ä»…é€‚ç”¨äº **MV / Online** æ¨ç†é…ç½®ï¼›è®­ç»ƒé˜¶æ®µå¯é€‰æ˜¯å¦è”åˆç›‘ç£ã€‚

### 4.1 `test_cfg` ä¸­å¼€å¯
```python
test_cfg = dict(
    merge_type='learnable_online',   # ç¡®ä¿è°ƒç”¨ OnlineMerge
    inscat_topk_insts=100,
    tformer_cfg=dict(
        type='TimeDividedTransformer',
        d_model=256,
        nhead=8,
        num_layers=3,
        dropout=0.0,
    ),
)
```
`OnlineMerge` æ£€æµ‹åˆ° `tformer_cfg` åä¼šå®ä¾‹åŒ– Transformer æ›¿ä»£åŸæœ‰æ··åˆåˆ†æ•°çŸ©é˜µã€‚

### 4.2 è®­ç»ƒç›‘ç£ï¼ˆå¯é€‰ï¼‰
è‹¥å¸Œæœ›å¯¹è·¨å¸§æ³¨æ„åŠ›çŸ©é˜µåŠ å…¥ç›‘ç£ï¼ˆ`CrossFrameCriterion`ï¼‰:
1. ç¡®è®¤ `oneformer3d/instance_criterion.py` ä¸­å·²é›†æˆè¯¥ lossï¼›
2. åœ¨ `model.criterion` å¯¹åº” loss æƒé‡é‡ŒåŠ å…¥ `L_match`, `L_cons`ã€‚

è®­ç»ƒç›‘ç£ (`CrossFrameCriterion`) å¯¹æ˜¾å­˜æ•æ„Ÿï¼Œå¯è®© `L_match=0.2, L_cons=0.05` èµ·æ­¥ã€‚

---

## 5. ç¤ºä¾‹é…ç½®é›†
| ä»»åŠ¡ | cfg æ–‡ä»¶ | å…³é”®æ”¹åŠ¨ |
| ---- | -------- | -------- |
| ScanNet200-SV (Bi-Fusion) | `configs/ESAM/ESAM_sv_scannet200_bifusion.py` | Section 3.1 & 3.2 |
| ScanNet200-MV (Bi-Fusion + T-former Online) | `configs/ESAM_CA/ESAM_online_scannet200_CA_bifusion_tf.py` | Section 3 + 4 |

å¤åˆ¶åŸ cfg å¹¶æŒ‰ç« èŠ‚æ›¿æ¢å­—æ®µå³å¯ã€‚

## 5.1 æ–°å¢ç¤ºä¾‹ cfg è·¯å¾„
- `configs/ESAM/online_scannet200_bifusion_tf.py`   â† **æ¨è** åœ¨çº¿å¤šå¸§æ–¹æ¡ˆ
- `configs/ESAM/online_scannet200_bifusion_only.py` â† ä»… 2D-3D èåˆï¼Œæ— è·¨å¸§åŒ¹é…

å¯åŸºäºå®˜æ–¹ `ESAM_online_scannet.py` å¤åˆ¶åæ”¹ä¸‰å¤„ï¼š`bi_encoder`, `clip_criterion`, `tformer_cfg`ã€‚

---

## 6. è®­ç»ƒ / æ¨ç†æŒ‡ä»¤æ¨¡æ¿
```bash
# å• GPU è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 \
python tools/train.py \
    <cfg_path>.py \
    --work-dir work_dirs/$(basename <cfg_path>)

# æ¨ç† / è¯„æµ‹
CUDA_VISIBLE_DEVICES=0 \
python tools/test.py \
    <cfg_path>.py \
    work_dirs/$(basename <cfg_path>)/epoch_*.pth \
    --work-dir work_dirs/$(basename <cfg_path>)
```
> è‹¥ä½¿ç”¨å¤š GPUï¼Œå¯åŠ  `--launcher pytorch` æˆ–æ”¹ç”¨ slurm åˆ†å¸ƒå¼è„šæœ¬ï¼Œå‡ä¸ MMEngine ä¿æŒä¸€è‡´ã€‚

---

## 7. æ•…éšœæ’æŸ¥ Checklist
1. **å†…å­˜ä¸è¶³**ï¼šé™ä½æ‰¹é‡ã€å¢å¤§ `freeze_blocks`ã€æˆ–å¯ç”¨æ··åˆç²¾åº¦ (`--amp`)ã€‚
2. **æ‰¾ä¸åˆ° `imgs` é”®**ï¼šæ£€æŸ¥ `with_img=True`ã€‚ç¡®ä¿æ•°æ®é›†ç›®å½•ä¸‹æœ‰ RGB png å¹¶åœ¨ meta ä¸­è®°å½•è·¯å¾„ã€‚
3. **tformer æ— æ•ˆæœ**ï¼šç¡®è®¤ `merge_type='learnable_online'` ä¸”æ•°æ®åŠ è½½ä¸º **MV**ï¼ˆåŒä¸€åºåˆ—å¤šå¸§ï¼‰ã€‚
4. **CLIP æƒé‡ä¸‹è½½å¤±è´¥**ï¼šæå‰æ‰‹åŠ¨æ”¾åˆ° `~/.cache/clip` æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ `OPENAI_CLIP_CACHE_PATH`ã€‚

---

## 8. å®æ–½ Checklist
| æ­¥éª¤ | ç›®çš„ | æ“ä½œ |
|------|------|------|
|â‘  dependency| ç¡®ä¿ `open_clip_torch` å¯ç”¨| `pip list | grep open_clip`|
|â‘¡ config     | Bi-Fusion & T-former å¼€å…³ | ä¿®æ”¹ cfg å¦‚ Â§3 Â§4|
|â‘¢ pipeline   | æä¾› RGB+Pose         | `with_img=True, with_cam=True`|
|â‘£ overfit-toy| å…ˆç”¨ 2-scene å¾®é›†è®­    | epoch=3, lr=1e-4 éªŒè¯å‰å‘ OK|
|â‘¤ full-train | ScanNet200 train      | 8Ã—GPU, batch=2, FP16|
|â‘¥ eval       | mIoU / AP50           | `tools/test.py`|
|â‘¦ compare    | ä¸ baseline å¯¹æ¯”      | è®°å½•æ—¥å¿— & TensorBoard|

> æ–‡æ¡£æ›´æ–°æ—¶é—´ï¼š2025-06-25
