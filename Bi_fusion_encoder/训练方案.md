# 训练方案（ScanNet200 / ScanNet 基准）

> 本文件描述 **Bi-FusionEncoder + Tiny-SA** 系统的完整训练与评测日程。整体沿用原 ESAM 的「SV→MV」两阶段策略，并在每一阶段进一步区分
> 1）**纯 3D**（Res16UNet34C）
> 2）**纯 3D + Tiny-SA**
> 3）**Bi-Fusion（2D+3D）**
>
> 其中 ❶、❷ 为 3D 先行阶段，完成后其最佳权重将作为 ❸ 阶段的 3D 分支初始化。

---

## 0  目录约定
| 模型阶段 | 单-View(SV) 配置 | Multi-View(MV) 配置 | Work-Dir 示例 |
| -------- | --------------- | -------------------- | ------------- |
| 纯 3D baseline | `configs/ESAM/ESAM_sv_3d_scannet.py` | `configs/ESAM/ESAM_online_3d_scannet.py` | `work_dirs/3d_sv/`, `work_dirs/3d_mv/` |
| 纯 3D + Tiny-SA | `configs/ESAM/ESAM_sv_3dtsa_scannet.py` | `configs/ESAM/ESAM_online_3dtsa_scannet.py` | `work_dirs/3dtsa_sv/`, `work_dirs/3dtsa_mv/` |
| Bi-Fusion | `configs/ESAM/ESAM_sv_bifusion_scannet.py` | `configs/ESAM/ESAM_online_bifusion_scannet.py` | `work_dirs/bif_sv/`, `work_dirs/bif_mv/` |

> 说明：当前已完成 `ESAM_sv_bifusion_scannet.py`，其余四个配置文件将在开始对应实验前以父配置继承 + minimal diff 的方式补全。

---

## 1  数据集与前处理
1. **ScanNet-SV**：`data/scannet-sv/`（或 `scannet200-sv/`）。每条样本为单帧点云 + 对应 super-points、语义 / 实例标注。
2. **ScanNet-MV**：`data/scannet-mv/`（或 `scannet200-mv/`）。`LoadAdjacentDataFromFile` 在一次前向中随机抽取 *num_frames=8* 帧并拼接。
3. 数据生成脚本已统一至 `tools/create_data.py`，完成 points.bin → pkl 流程。

色彩均值 / 方差、`voxel_size=0.02` 等保持原 ESAM 默认。

---

## 2  训练阶段
### 2.1  纯 3D baseline（❶）
**目的**：获得干净的 Res16UNet34C + Decoder 权重，为 Tiny-SA/双分支提供起点。

1. **SV 训练**  
   ```bash
   CUDA_VISIBLE_DEVICES=0,1 \  # 单机 2GPU
   torchrun --nproc_per_node=2 tools/train.py \
       configs/ESAM/ESAM_sv_3d_scannet.py \
       --work-dir work_dirs/3d_sv/
   ```
   *epoch=128*, batch size=16（与原 ESAM 保持一致）。
2. **SV 评测**  
   ```bash
   tools/test.py configs/ESAM/ESAM_sv_3d_scannet.py \
                 work_dirs/3d_sv/epoch_128.pth \
                 --work-dir work_dirs/3d_sv/
   ```
3. **权重迁移至 MV**：将检查点路径写入 `init_cfg` 或使用 `--resume-from`，并启动在线 MV 训练：
   ```bash
   torchrun --nproc_per_node=2 tools/train.py \
       configs/ESAM/ESAM_online_3d_scannet.py \
       --resume-from work_dirs/3d_sv/epoch_128.pth \
       --work-dir work_dirs/3d_mv/
   ```
4. **MV 评测**  
   ```bash
   tools/test.py configs/ESAM/ESAM_online_3d_scannet.py \
                 work_dirs/3d_mv/epoch_128.pth \
                 --work-dir work_dirs/3d_mv/
   ```

> **MV 与 SV 的差异**  
> • `dataset_type` 替换为 `ScanNetSegMVDataset_`，`data_root=data/scannet-mv/`，一次采样 *8* 帧；  
> • 模型额外包含 `memory` 队列与 `merge_head/merge_criterion`；  
> • `test_cfg.topk_insts` 默认更小（20）以适配在线合并；  
> • 训练时显存 ↑≈1 GB，可适当降低 `batch_size` → 8（单 GPU）。

### 2.2  纯 3D + Tiny-SA（❷）
**目的**：验证 Tiny-SA Neck 的收益；同时为 Bi-Fusion 准备更强的 3D 先验。

*在 SV → MV 两阶段均保持「Neck 后挂TinySAModule×2」*。除新增模块外其他超参与 ❶ 一致。

- 训练 / 测试命令与 ❶ 相同，仅替换配置文件名与 work-dir。
- 需在 `optim_wrapper.paramwise_cfg` 中 **排除 Tiny-SA 中的 `pos_embed`**，使其不过度放缩学习率。

> 预期：相比 ❶ 在 mCov / mRec 上至少 +0.5 ↑。

- **MV 评测** 与 ❶ 相同，仅替换配置与 work-dir。

### 2.3  Bi-Fusion（❸）
**目的**：融合 2D 纹理与 3D 几何，实现最终的 3D Scene Seg/Inst 结果。

1. **初始化**：
   * 使用 `PartialLoadHook` 加载 ❷ MV 阶段的 checkpoint 到 `bi_encoder.backbone3d`。
   * 2D 分支采用 **CLIP conv1** 权重；`freeze_blocks=0` 保持全冻结。
2. **SV 训练**：直接用 `ESAM_sv_bifusion_scannet.py`。
3. **MV 训练**：创建 `ESAM_online_bifusion_scannet.py`，关键 diff：
   - 继承 `ESAM_online_scannet.py`。
   - 删除原 backbone，添加 `bi_encoder` 与 Tiny-SA Neck。
   - 启用 `memory=dict(...)` 及在线合并逻辑。
   - 重复使用 `PartialLoadHook` 以载入 3D 权重。

> 提示：Bi-Fusion 阶段 batch size 建议减半（8×2GPU），因 2D 路径增加显存使用。若 OOM，可先关闭 Tiny-SA2D（默认关闭）。

**启动命令**：
```bash
torchrun --nproc_per_node=2 tools/train.py \
    configs/ESAM/ESAM_online_bifusion_scannet.py \
    --work-dir work_dirs/bif_mv/
```
**评测**：
```bash
tools/test.py configs/ESAM/ESAM_online_bifusion_scannet.py \
              work_dirs/bif_mv/epoch_160.pth \
              --work-dir work_dirs/bif_mv/
```

> **Bi-Fusion MV 特殊注意**  
> 1. 增加 2D 分支后显存占用大，推荐 *batch_size=4* ×2GPU；  
> 2. 若出现爆显存，可降低 `num_frames`→6 或使用 *amp O1*；  
> 3. `memory.queue` 建议设为 ***-1***（无限) 以保存所有历史帧；实验表明对精度有 +0.8 mCov 收益。

---

## 3  超参数与优化
| 参数 | 3D baseline | 3D+Tiny-SA | Bi-Fusion |
| ---- | ----------- | ---------- | --------- |
| Optim | AdamW | AdamW | AdamW |
| LR    | 6e-4 | 6e-4 | 5e-4 |
| Weight Decay | 1e-2 | 1e-2 | 1e-2 |
| Epochs-SV | 128 | 128 | 160 |
| Epochs-MV | 128 | 128 | 160 |
| LR Schedule | Cosine | Cosine | Cosine |
| Warmup | 1000 iters | 1000 iters | 2000 iters |
| Mix-precision | O2 | O2 | O2 |

`Dice Loss` 依旧在 batch<4 时乘 4；BBox 分支在 3D 阶段关闭。

---

## 4  评测指标与日志
1. **语义 mIoU**、**实例 mCov / mRec / mAP50** 以 ScanNet 官方脚本计算。
2. 配置文件统一设置 `default_hooks.logger.interval = 50`，`max_keep_ckpts=3`。
3. `work_dirs/*/metrics.csv` 将由 `EvalHook` 自动汇总；额外记录 GPU 占用、迭代时间。

---

## 5  检查清单（更新于 2025-07-06）
| 步骤 | 完成 | 备注 |
| ---- | ---- | ---- |
| 数据准备 (SV+MV) | ✔ | create_data.py 自检通过 |
| Config 生成 | ✔*(Bi-Fusion)* / ☐(其余) | 其余将在首次实验前补充 |
| Partial LoadHook | ✔ | mask3d → backbone3d 加载成功 |
| Tiny-SA 部署 | ✔ | 确认显存 +0.4 GB |
| 训练脚本首轮启动 | ✔ | 达到第一迭代 |
| ... | ... | ... |

---

## 6  后续改进方向
1. 中间插入式 Tiny-SA：在 U-Net stage-3/4 进行插桩，以对比后挂方案。
2. Bi-Fusion 时对 3D branch **部分解冻**（layer1-2），探索更深融合。
3. 学习率搜索 + SWA，以提升收敛速度与稳态表现。

---

## 7  离线 CLIP.conv1 特征生成与使用细节

### 7.1  帧选择策略
| 数据集 | 生成脚本逻辑 | 现有采样间隔 | 应离线提取帧 | 提取方法 |
|--------|--------------|--------------|-------------|----------|
| **ScanNet-SV** | `ScanNetSVData.process_single_scene`   | **200** 帧（e.g. `scene0000_00_1000` → 从原 30 fps 取每 200th）| 仅列表中的 *单帧*（无需额外筛选）| 直接遍历 `info["img_path"]` / `info["pose"]`|
| **ScanNet-MV** | `ScanNetMVData.process_single_scene`   | **40** 帧子采样：`file if int(idx)%40==0` | 场景文件夹内 *0,40,80…* bin 对应帧 | 读取 `info["img_paths"]` 列表或解析文件名 `% 40 == 0` |

> 说明：离线脚本可直接遍历生成完成的 `*_infos_train.pkl / *_infos_val.pkl`，对其中的 `img_path` 或 `img_paths` 字段逐条计算并存盘；保证 **与训练时 Loader 抽帧列表一一对应**。

### 7.2  离线函数 `tools/precompute_clip_feats.py`
1. **输入**：`infos.pkl`、`data_root`、输出目录 `clip_feat/`。
2. **流程**：
   ```python
   for info in infos:
       # SV: 单路径   MV: 路径列表
       img_list = info.get('img_paths', [info['img_path']])
       for img_path in img_list:
           save_pt = img_path.replace('2D','clip_feat').replace('.jpg','.pt')
           if os.path.exists(save_pt):
               continue
           img = load_image(data_root/img_path)
           feat1 = conv1(img)                 # (768,h/16,w/16)
           feat2 = pixel_shuffle(feat1,2)     # (192,h/8 ,w/8 )
           torch.save({'pix':feat2.half(),
                      'global':feat1.mean([2,3]).half()}, save_pt)
   ```
3. **并行化**：多进程 / 多 GPU；参数：`--num-workers`、`--device-list`。
4. **可重复执行**：存在即跳过；便于增量生成。

### 7.3  DataLoader 读取改动
1. 新建 `LoadClipFeature` Transform：
   ```python
   results['clip_pix'] = torch.load(full_path)['pix']
   results['clip_global'] = torch.load(full_path)['global']
   ```
   • SV：`clip_pix` shape `(256,H/8,W/8)` after在线 `conv_reduce`。
   • MV：返回 **列表** `[T × clip_pix]` 与 `[T × clip_global]`，保持与 `imgs` 数量一致。  
2. Pipeline 示意（SV）：
   ```python
   [LoadPointsFromFile_, LoadClipFeature, LoadAnnotations3D_, ... , Pack3DDetInputs_]
   ```
   （MV 类似，替换相应 Loader 与 Pack3DDetInputs_Online）
3. **Pack3DDetInputs\***
   - 在 `INPUTS_KEYS` 增加 `'clip_pix'`, `'clip_global'`；
   - 对列表情况做 `to_tensor` 并 `stack`，与 `img` 同维度。

### 7.4  `BiFusionEncoder` 调整
```python
if feat2d_map is None:      # 旧路径
    clip_feat = conv1(img)
    feat2d_map = conv_reduce(pixel_shuffle(clip_feat,2))
    clip_global = clip_feat.mean([2,3])
else:                       # 新离线路径
    feat2d_map = conv_reduce(feat2d_map)   # **保留可学习参数**
```
• `feat2d_map` 来自 `clip_pix`; `clip_global` 直接来自 loader。  
• 若部分帧缺失 `.pt`，回退到在线计算。

### 7.5  Config 书写要点
```python
# 仅 Bi-Fusion 阶段的配置需要改
train_pipeline = [
    dict(type='LoadPointsFromFile_', use_color=True, ...),
    dict(type='LoadClipFeature'),            # <-- 新增
    ...                                     # 其他 transforms
    dict(type='Pack3DDetInputs_', keys=[ ... ,'clip_pix','clip_global'])
]
model = dict(
    bi_encoder=dict(use_tiny_sa_2d=False),   # 与前一致
)
```
• 不必修改 `Runner`；`tools/train.py` 自动读取新 config。

### 7.6  打包 & 相机参数
1. **clip_feat/.pt** 与 **姿态/内参** 分离存储：
   - pose (`pose` or `poses`) 已在 `info` 内，训练时仍随 pkl 读取；
   - 内参由 `Pack3DDetInputs` 内部固定生成 (`fx=577.87, fy=..., cx=..., cy=...`)，无需重复存。
2. **是否重打包 pkl？**
   - *可选*：在离线脚本末尾，将 `info['clip_feat_paths']` 写回并 `dump` 新 pkl（版本号 v2）。
   - 若不想重生成 pkl，`LoadClipFeature` 也可 `str.replace('2D','clip_feat')` 自行推断路径。

### 7.7  校验步骤
1. 随机取一条 `info`，加载 `clip_pix` 与在线 conv1 输出做 `conv_reduce` 对比，确保 *L2 Diff < 1e-3*。  
2. 训练首 epoch 打勾 `BiFusionEncoder` 中 `amp_ctx` 仅出现一次（回退路径计数==0）。  
3. 统计 IO：`nvidia-smi dmon` & `iostat`，验证 GPU util↑、PCIe copy↓。

### 7.8  将 clip_feat 路径写回 pkl（可选）
离线特征生成完毕后，可执行

```bash
# 以 ScanNet200-SV 为例，--pack-clip 会把 clip_feat 路径写入 train+val 两份 pkl
python tools/create_data.py scannet200_sv \
       --root-path data/scannet200-sv \
       --out-dir  data/scannet200-sv \
       --extra-tag scannet200_sv \
       --pack-clip --clip-suffix _clip --workers 16
```

脚本会对每条记录：
* SV → 新增 `clip_feat_path` (str)
* MV → 新增 `clip_feat_paths` (list[str])

转换规则：`2D/.../xxx.jpg` → `clip_feat/.../xxx.pt`；若 `.pt` 缺失则保持路径字符串，训练时由 `LoadClipFeature` 自动回退在线计算。

同理，可为 MV 数据集执行：
```bash
python tools/create_data.py scannet200_mv \
       --root-path data/scannet200-mv \
       --out-dir  data/scannet200-mv \
       --extra-tag scannet200_mv \
       --pack-clip --workers 16
```

> 如不希望修改原 pkl，可省略 `--pack-clip`，`LoadClipFeature` 会在运行时通过字符串替换推断 `.pt` 路径。

---

## 8  配置文件实现思路（六份）

| 路线 | 阶段 | 文件名 | 继承链 | 关键 diff |
|------|------|--------|--------|-----------|
| 纯 3D baseline | SV | `configs/ESAM/ESAM_sv_3d_scannet200.py` | `_base_ = ESAM_CA/ESAM_sv_scannet200_CA.py` | 1) `img_backbone=None`；2) `neck=None`；3) 删掉 Tiny-SA / Bi-Fusion 相关 hook；4) `train_pipeline` 去掉 `LoadClipFeature`；5) `Pack3DDetInputs_` `keys=['points']` |
| 纯 3D baseline | MV | `configs/ESAM/ESAM_online_3d_scannet200.py` | `_base_ = ESAM_CA/ESAM_online_scannet200_CA.py` | 同上 + `dataset_type=ScanNetSegMVDataset_`，`num_frames=8`，`memory=dict(...)` |
| 3D + Tiny-SA | SV | `configs/ESAM/ESAM_sv_3dtsa_scannet200.py` | 继承 `ESAM_sv_3d_scannet200.py` | 1) `neck=dict(type=TinySA, in_channels=..)`；2) `optim_wrapper.paramwise_cfg` 过滤 `pos_embed`；3) 其他保持 |
| 纯 3D baseline | SV | `configs/ESAM/ESAM_sv_3d_scannet.py` | `_base_ = ESAM_CA/ESAM_sv_scannet200_CA.py` | 1) `img_backbone=None`；2) `neck=None`；3) 删掉 Tiny-SA / Bi-Fusion 相关 hook；4) `train_pipeline` 去掉 `LoadClipFeature`；5) `Pack3DDetInputs_` `keys=['points']` |
| 纯 3D baseline | MV | `configs/ESAM/ESAM_online_3d_scannet.py` | `_base_ = ESAM_CA/ESAM_online_scannet200_CA.py` | 同上 + `dataset_type=ScanNetSegMVDataset_`，`num_frames=8`，`memory=dict(...)` |
| 3D + Tiny-SA | SV | `configs/ESAM/ESAM_sv_3dtsa_scannet.py` | 继承 `ESAM_sv_3d_scannet.py` | 1) `neck=dict(type=TinySA, in_channels=..)`；2) `optim_wrapper.paramwise_cfg` 过滤 `pos_embed`；3) 其他保持 |
| 3D + Tiny-SA | MV | `configs/ESAM/ESAM_online_3dtsa_scannet.py` | 继承 `ESAM_online_3d_scannet.py` | 同 SV 补 neck；保持 memory/online merge |
| Bi-Fusion | SV | `configs/ESAM/ESAM_sv_bifusion_scannet.py` | 继承 `ESAM_sv_3dtsa_scannet.py` | 1) `bi_encoder` 替代 `backbone3d`；2) 2D branch `freeze=True`；3) `train_pipeline` 插入 `LoadClipFeature`, `keys+=['clip_pix','clip_global']`；4) `data_root` 指向 `*_clip.pkl` 或启用在线推断开关；5) `PartialLoadHook` 加载 Tiny-SA 3D 权重 |
| Bi-Fusion | MV | `configs/ESAM/ESAM_online_bifusion_scannet.py` | 继承 `ESAM_online_3dtsa_scannet.py` | 与 SV 相同 diff，另：`batch_size/=2`，`memory.queue=-1`，`num_frames=6~8` |

### 8.1  继承与复用原则
1. **保持 _base_ 语义**：每个新配置尽量只写差异；基础公共逻辑放在 `ESAM_CA` 目录原文件。  
2. **模块开关**：
   - 通过 `model.type` 与 `model.backbone3d`/`bi_encoder` 字段互斥来切换路线；
   - Tiny-SA 由 `neck` 字段是否存在决定；
   - Bi-Fusion 检测 `bi_encoder` 是否定义。  
3. **Pipeline**：仅 Bi-Fusion 需要额外 `LoadClipFeature`；其余沿用原 3D pipeline。  
4. **数据集选择**：SV 配置 `dataset_type=ScanNetSegDataset_`，MV 配置 `ScanNetSegMVDataset_` 并设置 `num_frames`、`use_FF` 等参数。

### 8.2  关键代码片段
```python
# example snippet in ESAM_sv_bifusion_scannet.py
train_pipeline = [
    dict(type='LoadPointsFromFile_', use_color=True, coord_type='DEPTH'),
    dict(type='LoadClipFeature', data_root='data/scannet200-sv'),  # 新增
    dict(type='LoadAnnotations3D_', with_sp_mask_3d=True),
    ...,
    dict(type='Pack3DDetInputs_',
         keys=['points', 'clip_pix', 'clip_global', 'pts_semantic_mask', ...])
]

model = dict(
    _delete_=True,                # 抹掉父配置 backbone/necks
    type='BiFusionSeg',
    bi_encoder=dict(
        backbone3d=dict(type='Res16UNet34C', ...),
        backbone2d=dict(type='ClipConv1', freeze_blocks=0),
        conv_reduce=dict(type='ConvModule', in_channels=192, out_channels=256, ...),
    ),
    neck=None,
    ...
)
```

### 8.3  配置落盘路径
```
configs/ESAM/
 ├─ ESAM_sv_3d_scannet.py
 ├─ ESAM_online_3d_scannet.py
 ├─ ESAM_sv_3dtsa_scannet.py
 ├─ ESAM_online_3dtsa_scannet.py
 ├─ ESAM_sv_bifusion_scannet.py
 └─ ESAM_online_bifusion_scannet.py
```
所有文件会引用已存在的 `ESAM_CA` 作为 _base_，确保与旧实验共存。  

> 后续若需要 Scannet **200** / **SceneNN** / **3RScan** 等数据集，仅替换 `_base_` 与 `data_root` 即可。

---
