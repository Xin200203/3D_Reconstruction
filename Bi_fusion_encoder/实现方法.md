## 特征提取 - Bi-Fusion Encoder（最终版本）

> **目标**：单帧内将 2D-VFM 的强语义特征与 3D-U-Net 的几何/拓扑特征 **同步编码并对齐**，
> 同时显式嵌入世界坐标几何 **Geo-PE**，再通过 **Confidence-Aware View Pooling + 门控融合** 得到鲁棒、可微、时序一致的点云 latent $96 d$。
> 该 latent 既作为 **单帧实例分割解码器** 的输入，也作为 **跨帧 Slot-Transformer** 的匹配 Query / Key。

---

### 1. 2D 语义分支

| 步骤                    | 细节                                             | 输出维度            |
| --------------------- | ---------------------------------------------- | --------------- |
| **(a) VFM Backbone**  | CLIP-ViT-B/16（冻结或微调最后 2 Block）                 | *H×W×512*       |
| **(b) 上采样 + 线性**      | 2×2 PixelShuffle + Conv1×1                     | *H×W×256*       |
| **(c) Mask-aware 抽样** | 以深度阈值\~occ-mask 筛选可投影像素                        | \$N\_{vis}\$ 像素 |

$$
F^{2D}_{i}\in\mathbb R^{256},\quad i=1..N_{vis}
$$

---

### 2. 3D 几何分支

| 步骤                   | 细节                                                                                                        | 输出维度       |
| -------------------- | --------------------------------------------------------------------------------------------------------- | ---------- |
| **(a) 投影**           | 将 $(u,v,d)$ → camera → world，生成稀疏点云 $P$                                                                   | \$N\_p\$ 点 |
| **(b) Sparse U-Net** | KPConv encoder（4 Down / 4 Up）                                                                             | *N\_p×128* |
| **(c) Tiny-SA × 2**  | Bottleneck 3 k token （FPS 下采样）<br> • Multi-Head Local SA（邻域 0.3 m，d\_m=128）<br> • FeedForward + LayerNorm | *N\_p×128* |

$$
F^{3D}_{j}\in\mathbb R^{128},\quad j=1..N_p
$$

---

### 3. **Geo-PE**（显式位置编码，64 d）

$$
\underbrace{\big[\;\sin(2^k\pi x),\,\cos(2^k\pi x)\big]_{k=0}^{7}}_{世界坐标~xyz~(48d)}
\;||\;
\underbrace{\mathbf t_{\Delta}\in\mathbb R^{12}}_{\text{相机位姿残差 }(\hat R,\,\hat t)}
\;||\;
\underbrace{h}_{\text{地面高度}(1d)}
$$

> * **CNN/ViT 不易感知绝对尺度**，高频 sin-cos 让几何距离线性可分；
> * 用残差位姿 $\mathbf t_{\Delta}=T_{cam\rightarrow world}-T_{ref}$ 提供 **时序连续位移** 线索；
> * 单维高度 $h$ 有助区分“天花/地面/桌面”等结构。

64 d 的 PE 经过 `MLP(64→32, ReLU, 32→32)` 与原始特征 **拼接**：

$$
\tilde F^{2D}= \big[F^{2D}\;||\;\text{PE}\big]\in\mathbb R^{288},\qquad
\tilde F^{3D}= \big[F^{3D}\;||\;\text{PE}\big]\in\mathbb R^{160}
$$

随后各自用 `Linear → 96d` 对齐维度。

---

### 4. 多尺度门控融合（FusionGate）

对每个金字塔层 $\ell$：

$$
\mathbf z^\ell = \sigma\!\big(\mathrm{MLP}_g^\ell([\bar F^{2D\,\ell} || \tilde F^{3D\,\ell}])\big)\;\odot\; \bar F^{2D\,\ell}
\;+\;
\big(1-\sigma(\cdot)\big)\odot \tilde F^{3D\,\ell}
$$

* \$\sigma\$ 为 Sigmoid，产生 **通道级门控**；
* MLP\_g 输入 192 d，隐藏 64，输出 96 gate 值。
* 分别在两条 U-Net skip connection 上执行，可保留局部纹理与远程几何。

输出统一 96 d latent：$F^{fusion} \in\mathbb R^{N_p \times 96}$。

---

### 5. 语义一致性正则（CLIP-Cons Loss）

在**阶段-I（静态图）预训练**中，对每个点：

$$
\mathcal L_{\text{clip}} = \lambda_c\;\bigl(1 - 
\cos\bigl(F^{fusion},\; \text{stopgrad}(\bar F^{2D}_{\text{CLIP}})\bigr)\bigr)
$$

* **stop-gradient**：不更新 2D CLIP，防止过拟合；
* 实际训练 Loss：

  $$
  \mathcal L = \mathcal L_{\text{sem}}+\mathcal L_{\text{geo}}+\mathcal L_{\text{clip}}
  $$

  其中语义、几何损失与 ESAM/Mask3D 相同（交叉熵+Lovász/Chamfer）。

**意义**：

* 仅作为正则，而非蒸馏删除 2D 路径 → **保留实时泛化**；
* 提供开放词表对齐，提升小样本/零样本语义识别。

---

### 6. TinySA-U-Net Bottleneck回顾

> 放在 U-Net 最低分辨率 (≈3 k token)
> **Local Window SA**（r=0.3 m）可捕获家具级长距接触；
> 2 层足够＋保证显存：
>
> $$
> \mathbf h' = \text{SA}\bigl(\mathbf h + \text{PE}\bigr);\quad \mathbf h\_2 = \text{FFN}(\mathbf h')+\mathbf h'
> $$

输出与上节融合后的特征一起回传上采样，最终得到 **每点 96 d 表征**。

---

## 7. 输出接口

| 名称            | 张量           | 说明                                         |
| ------------- | ------------ | ------------------------------------------ |
| `feat_fusion` | *(N\_p, 96)* | 时刻 t 融合后点特征，送单帧 Decoder & Slot-Transformer |
| `conf_2d`     | *(N\_p, 1)*  | 归一化 \$\sum\_k w\_k\$，可视化质量／硬阈值             |
| `pe_xyz`      | *(N\_p, 32)* | 低频 + 高频 sin-cos，仅供调研                       |

---

### 总结 & 关键理解

1. **正则而非蒸馏**：蒸馏 = 让 3D CNN 完全替代 2D；我们只把 CLIP 视作“软锚点”，训练后依旧实时读取最新帧 2D 信息，避免特征陈旧。
2. **Geo-PE 必要性**：显式高频位置使同类物体不同空间处易区分，也为跨帧几何一致打下基础。
3. **端到端可微**：所有步骤（投影、权重、加权平均、门控）都用 differentiable tensor op 实现，可与 Slot-Transformer、Decoder 共同反传。
